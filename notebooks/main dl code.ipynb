{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11bd6c63",
        "outputId": "3cf5cd65-16f2-491b-dcd5-c373c10fc50e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "AL2zvwxbizvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj40N78wtyd0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Dataset preparation\n",
        "# ========================\n",
        "class RetinaMultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, labels\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pTbWMB4GulY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# build model\n",
        "# ========================\n",
        "def build_model(backbone=\"resnet18\", num_classes=3, pretrained=True):\n",
        "\n",
        "    if backbone == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif backbone == \"efficientnet\":\n",
        "        model = models.efficientnet_b0(pretrained=pretrained)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported backbone\")\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oFg46E34jmbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# model training and val\n",
        "# ========================\n",
        "def train_one_backbone(backbone, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir,\n",
        "                       epochs=10, batch_size=32, lr=1e-4, img_size=256, save_dir=\"checkpoints\",pretrained_backbone=None, mode=\"full_fine_tuning\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # transforms\n",
        "    train_transform = transforms.Compose([\n",
        "      transforms.Resize((img_size, img_size)),\n",
        "      Augmentations:\n",
        "      transforms.RandomHorizontalFlip(p=0.5),\n",
        "      transforms.RandomVerticalFlip(p=0.5),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "      transforms.Resize((img_size, img_size)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "    # dataset & dataloader\n",
        "    train_ds = RetinaMultiLabelDataset(train_csv, train_image_dir, train_transform)\n",
        "    val_ds   = RetinaMultiLabelDataset(val_csv, val_image_dir, val_transform)\n",
        "    test_ds  = RetinaMultiLabelDataset(test_csv, test_image_dir, val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # model\n",
        "    model = build_model(backbone, num_classes=3, pretrained=False).to(device)\n",
        "\n",
        "    # load pretrained backbone\n",
        "    if pretrained_backbone is not None:\n",
        "        state_dict = torch.load(pretrained_backbone, map_location=\"cpu\")\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "    if mode == \"no_fine_tuning\":\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = False\n",
        "    elif mode == \"frozen_backbone\":\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = False\n",
        "        if backbone == \"resnet18\":\n",
        "            for p in model.fc.parameters():\n",
        "                p.requires_grad = True\n",
        "        elif backbone == \"efficientnet\":\n",
        "            for p in model.classifier.parameters():\n",
        "                p.requires_grad = True\n",
        "    elif mode == \"full_fine_tuning\":\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "    # loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    # training\n",
        "    best_val_loss = float(\"inf\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    ckpt_path = os.path.join(save_dir, f\"best_{backbone}.pt\")\n",
        "\n",
        "\n",
        "    if mode == \"no_fine_tuning\":\n",
        "        print(\"skip training!\")\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "    else:\n",
        "      # optimizer\n",
        "      optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "      for epoch in range(epochs):\n",
        "          model.train()\n",
        "          train_loss = 0\n",
        "          for imgs, labels in train_loader:\n",
        "              imgs, labels = imgs.to(device), labels.to(device)\n",
        "              optimizer.zero_grad()\n",
        "              outputs = model(imgs)\n",
        "              loss = criterion(outputs, labels)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "          train_loss /= len(train_loader.dataset)\n",
        "\n",
        "          # validation\n",
        "          model.eval()\n",
        "          val_loss = 0\n",
        "          with torch.no_grad():\n",
        "              for imgs, labels in val_loader:\n",
        "                  imgs, labels = imgs.to(device), labels.to(device)\n",
        "                  outputs = model(imgs)\n",
        "                  loss = criterion(outputs, labels)\n",
        "                  val_loss += loss.item() * imgs.size(0)\n",
        "          val_loss /= len(val_loader.dataset)\n",
        "\n",
        "          print(f\"[{backbone}] Epoch {epoch+1}/{epochs} Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "          # save best\n",
        "          if val_loss < best_val_loss:\n",
        "              best_val_loss = val_loss\n",
        "              torch.save(model.state_dict(), ckpt_path)\n",
        "              print(f\"Saved best model for {backbone} at {ckpt_path}\")\n",
        "\n",
        "    # ========================\n",
        "    # testing\n",
        "    # ========================\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = torch.tensor(y_true).numpy()\n",
        "    y_pred = torch.tensor(y_pred).numpy()\n",
        "\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "\n",
        "    for i, disease in enumerate(disease_names):  #compute metrics for every disease\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        acc = accuracy_score(y_t, y_p)\n",
        "        precision = precision_score(y_t, y_p, average=\"macro\",zero_division=0)\n",
        "        recall = recall_score(y_t, y_p, average=\"macro\",zero_division=0)\n",
        "        f1 = f1_score(y_t, y_p, average=\"macro\",zero_division=0)\n",
        "        kappa = cohen_kappa_score(y_t, y_p)\n",
        "\n",
        "        print(f\"{disease} Results [{backbone}]\")\n",
        "        print(f\"Accuracy : {acc:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall   : {recall:.4f}\")\n",
        "        print(f\"F1-score : {f1:.4f}\")\n",
        "        print(f\"Kappa    : {kappa:.4f}\")\n",
        "\n",
        "    # ========================\n",
        "    # prediction generating\n",
        "    # ========================\n",
        "    print(\"Saving predictions to final_onsite_prediction.csv\")\n",
        "    ids = pd.read_csv(test_csv)['id']\n",
        "    onsite_prediction = pd.DataFrame(y_pred, columns=['D', 'G', 'A'])\n",
        "    onsite_prediction.insert(0, 'id', ids)\n",
        "    onsite_prediction.to_csv(\"/content/drive/MyDrive/Colab Notebooks/final_project_resources/predictions/final_onsite_prediction.csv\", index=False) # replace with your own test label file path"
      ],
      "metadata": {
        "id": "iSAROHBGjqJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# main Task1.1, 1.2, 1.3\n",
        "# ========================\n",
        "if __name__ == \"__main__\":\n",
        "    train_csv = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources/train.csv\" # replace with your own train label file path\n",
        "    val_csv   = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources/val.csv\" # replace with your own validation label file path\n",
        "    test_csv  = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources/offsite_test.csv\"  # replace with your own test label file path\n",
        "    train_image_dir =\"/content/drive/MyDrive/Colab Notebooks/final_project_resources/images/train\"   # replace with your own train image floder path\n",
        "    val_image_dir = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources/images/val\"  # replace with your own validation image floder path\n",
        "    test_image_dir = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources/images/offsite_test\" # replace with your own test image floder path\n",
        "    save_dir = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints\"\n",
        "    pretrained_backbone = '/content/drive/MyDrive/Colab Notebooks/final_project_resources/pretrained_backbone/ckpt_resnet18_ep50.pt'  # replace with your own pretrained backbone path\n",
        "    backbone = 'resnet18'  # backbone choices: [\"resnet18\", \"efficientnet\"]\n",
        "    train_one_backbone(backbone, train_csv, val_csv, test_csv, train_image_dir, val_image_dir, test_image_dir,\n",
        "                          epochs=50, batch_size=32, lr=1e-5, img_size=256, save_dir=save_dir,\n",
        "                          pretrained_backbone=pretrained_backbone, mode=\"full_fine_tuning\") # mode options: [\"no_fine_tuning\", \"frozen_backbone\", \"full_fine_tuning\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGPxHuRyjud2",
        "outputId": "032dd2ba-0398-4900-9ef8-09cb64a4b10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[resnet18] Epoch 1/50 Train Loss: 1.4598 Val Loss: 1.1865\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 2/50 Train Loss: 1.0537 Val Loss: 1.0278\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 3/50 Train Loss: 0.7984 Val Loss: 0.8737\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 4/50 Train Loss: 0.6190 Val Loss: 0.7798\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 5/50 Train Loss: 0.5253 Val Loss: 0.7400\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 6/50 Train Loss: 0.4534 Val Loss: 0.6833\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 7/50 Train Loss: 0.3913 Val Loss: 0.6663\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 8/50 Train Loss: 0.3522 Val Loss: 0.6493\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 9/50 Train Loss: 0.3006 Val Loss: 0.6223\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 10/50 Train Loss: 0.2790 Val Loss: 0.6281\n",
            "[resnet18] Epoch 11/50 Train Loss: 0.2470 Val Loss: 0.6120\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 12/50 Train Loss: 0.2209 Val Loss: 0.6111\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 13/50 Train Loss: 0.2020 Val Loss: 0.5972\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 14/50 Train Loss: 0.1932 Val Loss: 0.5974\n",
            "[resnet18] Epoch 15/50 Train Loss: 0.1742 Val Loss: 0.5981\n",
            "[resnet18] Epoch 16/50 Train Loss: 0.1691 Val Loss: 0.5912\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 17/50 Train Loss: 0.1341 Val Loss: 0.6001\n",
            "[resnet18] Epoch 18/50 Train Loss: 0.1487 Val Loss: 0.5998\n",
            "[resnet18] Epoch 19/50 Train Loss: 0.1179 Val Loss: 0.5974\n",
            "[resnet18] Epoch 20/50 Train Loss: 0.1237 Val Loss: 0.5954\n",
            "[resnet18] Epoch 21/50 Train Loss: 0.0978 Val Loss: 0.5909\n",
            "Saved best model for resnet18 at /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18.pt\n",
            "[resnet18] Epoch 22/50 Train Loss: 0.1041 Val Loss: 0.6059\n",
            "[resnet18] Epoch 23/50 Train Loss: 0.0767 Val Loss: 0.6067\n",
            "[resnet18] Epoch 24/50 Train Loss: 0.0795 Val Loss: 0.6000\n",
            "[resnet18] Epoch 25/50 Train Loss: 0.0637 Val Loss: 0.6007\n",
            "[resnet18] Epoch 26/50 Train Loss: 0.0565 Val Loss: 0.6104\n",
            "[resnet18] Epoch 27/50 Train Loss: 0.0527 Val Loss: 0.5947\n",
            "[resnet18] Epoch 28/50 Train Loss: 0.0496 Val Loss: 0.6034\n",
            "[resnet18] Epoch 29/50 Train Loss: 0.0501 Val Loss: 0.6138\n",
            "[resnet18] Epoch 30/50 Train Loss: 0.0519 Val Loss: 0.6011\n",
            "[resnet18] Epoch 31/50 Train Loss: 0.0420 Val Loss: 0.6028\n",
            "[resnet18] Epoch 32/50 Train Loss: 0.0352 Val Loss: 0.6047\n",
            "[resnet18] Epoch 33/50 Train Loss: 0.0362 Val Loss: 0.6033\n",
            "[resnet18] Epoch 34/50 Train Loss: 0.0358 Val Loss: 0.5973\n",
            "[resnet18] Epoch 35/50 Train Loss: 0.0331 Val Loss: 0.5999\n",
            "[resnet18] Epoch 36/50 Train Loss: 0.0369 Val Loss: 0.6090\n",
            "[resnet18] Epoch 37/50 Train Loss: 0.0277 Val Loss: 0.5999\n",
            "[resnet18] Epoch 38/50 Train Loss: 0.0256 Val Loss: 0.6102\n",
            "[resnet18] Epoch 39/50 Train Loss: 0.0237 Val Loss: 0.5995\n",
            "[resnet18] Epoch 40/50 Train Loss: 0.0228 Val Loss: 0.5993\n",
            "[resnet18] Epoch 41/50 Train Loss: 0.0236 Val Loss: 0.6044\n",
            "[resnet18] Epoch 42/50 Train Loss: 0.0213 Val Loss: 0.6097\n",
            "[resnet18] Epoch 43/50 Train Loss: 0.0204 Val Loss: 0.6140\n",
            "[resnet18] Epoch 44/50 Train Loss: 0.0214 Val Loss: 0.6140\n",
            "[resnet18] Epoch 45/50 Train Loss: 0.0192 Val Loss: 0.6190\n",
            "[resnet18] Epoch 46/50 Train Loss: 0.0178 Val Loss: 0.6075\n",
            "[resnet18] Epoch 47/50 Train Loss: 0.0164 Val Loss: 0.6184\n",
            "[resnet18] Epoch 48/50 Train Loss: 0.0143 Val Loss: 0.6231\n",
            "[resnet18] Epoch 49/50 Train Loss: 0.0177 Val Loss: 0.6219\n",
            "[resnet18] Epoch 50/50 Train Loss: 0.0144 Val Loss: 0.6165\n",
            "DR Results [resnet18]\n",
            "Accuracy : 0.7950\n",
            "Precision: 0.7588\n",
            "Recall   : 0.7821\n",
            "F1-score : 0.7673\n",
            "Kappa    : 0.5362\n",
            "Glaucoma Results [resnet18]\n",
            "Accuracy : 0.8900\n",
            "Precision: 0.8803\n",
            "Recall   : 0.8100\n",
            "F1-score : 0.8371\n",
            "Kappa    : 0.6759\n",
            "AMD Results [resnet18]\n",
            "Accuracy : 0.9150\n",
            "Precision: 0.7817\n",
            "Recall   : 0.7929\n",
            "F1-score : 0.7872\n",
            "Kappa    : 0.5744\n",
            "Saving predictions to final_onsite_prediction.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "VGBUzhTepq2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet+focal loss\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\" Device: {device}\")\n",
        "\n",
        "# ====================================================================\n",
        "# FOCAL LOSS ONLY\n",
        "# ====================================================================\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.75, gamma=2.5):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        probs = torch.sigmoid(inputs)\n",
        "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
        "        focal_weight = (1 - p_t) ** self.gamma\n",
        "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "        focal_loss = alpha_t * focal_weight * BCE_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# ====================================================================\n",
        "# CLASS-BALANCED LOSS ONLY\n",
        "# ====================================================================\n",
        "class ClassBalancedLoss(nn.Module):\n",
        "    def __init__(self, samples_per_class, beta=0.9999):\n",
        "        super(ClassBalancedLoss, self).__init__()\n",
        "        self.samples_per_class = torch.tensor(samples_per_class, dtype=torch.float32)\n",
        "        self.beta = beta\n",
        "\n",
        "        effective_num = 1.0 - torch.pow(self.beta, self.samples_per_class)\n",
        "        weights = (1.0 - self.beta) / effective_num\n",
        "        self.weights = weights / weights.sum() * len(weights)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        weights = self.weights.to(inputs.device)\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        weighted_loss = BCE_loss * weights.unsqueeze(0)\n",
        "        return weighted_loss.mean()\n",
        "\n",
        "# ====================================================================\n",
        "# DATASET\n",
        "# ====================================================================\n",
        "class RetinaDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, labels\n",
        "\n",
        "# ====================================================================\n",
        "# MODEL\n",
        "# ====================================================================\n",
        "def build_model(backbone=\"resnet18\", num_classes=3, dropout=0.5):\n",
        "    if backbone == \"resnet18\":\n",
        "        model = models.resnet18(weights=None)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "    elif backbone == \"efficientnet\":\n",
        "        model = models.efficientnet_b0(weights=None)\n",
        "        num_features = model.classifier[1].in_features\n",
        "        model.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# ====================================================================\n",
        "# TRAINING FUNCTION\n",
        "# ====================================================================\n",
        "def train_task2(backbone, loss_fn, loss_name, train_csv, val_csv, test_csv,\n",
        "               train_image_dir, val_image_dir, test_image_dir,\n",
        "               pretrained_backbone, epochs=60, batch_size=12, lr=2e-5):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((288, 288)),\n",
        "        transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
        "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.15),\n",
        "        transforms.RandomGrayscale(p=0.1),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        transforms.RandomErasing(p=0.4, scale=(0.02, 0.2)),\n",
        "    ])\n",
        "\n",
        "    val_test_transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_ds = RetinaDataset(train_csv, train_image_dir, train_transform)\n",
        "    val_ds = RetinaDataset(val_csv, val_image_dir, val_test_transform)\n",
        "    test_ds = RetinaDataset(test_csv, test_image_dir, val_test_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                             num_workers=2, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
        "                           num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(f\" Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
        "\n",
        "    model = build_model(backbone, num_classes=3, dropout=0.5).to(device)\n",
        "\n",
        "    pretrained_dict = torch.load(pretrained_backbone, map_location=device)\n",
        "    model_dict = model.state_dict()\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
        "                      if k in model_dict and v.shape == model_dict[k].shape}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict, strict=False)\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr*3, epochs=epochs,\n",
        "                                             steps_per_epoch=len(train_loader), pct_start=0.1)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    best_val_f1 = 0.0\n",
        "    patience_counter = 0\n",
        "    max_patience = 20\n",
        "\n",
        "    save_dir = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources/task2\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    ckpt_path = os.path.join(save_dir, f\"{backbone}_{loss_name}.pt\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" TASK 2: {backbone} + {loss_name}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(imgs)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(imgs)\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                val_loss += loss.item() * imgs.size(0)\n",
        "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "                preds = (probs > 0.5).astype(int)\n",
        "                all_preds.extend(preds)\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        all_preds = np.array(all_preds)\n",
        "        all_labels = np.array(all_labels)\n",
        "        val_f1s = [f1_score(all_labels[:, i], all_preds[:, i], average='binary', zero_division=0) for i in range(3)]\n",
        "        val_f1 = np.mean(val_f1s)\n",
        "\n",
        "        print(f\"E{epoch+1:02d}/{epochs} | Train:{train_loss:.4f} | Val:{val_loss:.4f} | F1:{val_f1:.4f}\")\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            torch.save(model.state_dict(), ckpt_path)\n",
        "            print(f\"   BEST! F1: {val_f1:.4f}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= max_patience:\n",
        "            print(f\"\\n Early stop at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\n Complete! Best Val F1: {best_val_f1:.4f}\\n\")\n",
        "    return ckpt_path, test_loader\n",
        "\n",
        "def evaluate_task2(model_path, backbone, test_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = build_model(backbone, num_classes=3, dropout=0.5).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(imgs)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "    results = {}\n",
        "    f1_scores = []\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" OFFSITE TEST EVALUATION\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"{'Disease':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        p = precision_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        r = recall_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        results[disease] = {'precision': p, 'recall': r, 'f1_score': f1}\n",
        "        f1_scores.append(f1)\n",
        "        print(f\"{disease:<15} {p:<12.4f} {r:<12.4f} {f1:<12.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    results['average_f1'] = avg_f1\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'AVG F1:':<15} {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    return results\n",
        "\n",
        "def generate_submission(model_path, backbone, onsite_csv, onsite_image_dir, output_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = build_model(backbone, num_classes=3, dropout=0.5).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    submission_df = pd.read_csv(onsite_csv)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for img_name in submission_df['id'].values:\n",
        "            img = Image.open(os.path.join(onsite_image_dir, img_name)).convert(\"RGB\")\n",
        "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(img_tensor)\n",
        "            probs = torch.sigmoid(output).cpu().numpy()[0]\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            predictions.append(preds)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    submission_df['D'] = predictions[:, 0]\n",
        "    submission_df['G'] = predictions[:, 1]\n",
        "    submission_df['A'] = predictions[:, 2]\n",
        "    submission_df.to_csv(output_name, index=False)\n",
        "    print(f\" Saved: {output_name}\\n\")\n",
        "    return submission_df\n",
        "\n",
        "print(\" All functions loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgu1WspRqXie",
        "outputId": "c845312c-a081-495c-af76-44d98ea6bc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " Device: cuda\n",
            " All functions loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources\"\n",
        "train_csv = f\"{base_path}/train.csv\"\n",
        "val_csv = f\"{base_path}/val.csv\"\n",
        "test_csv = f\"{base_path}/offsite_test.csv\"\n",
        "train_image_dir = f\"{base_path}/images/train\"\n",
        "val_image_dir = f\"{base_path}/images/val\"\n",
        "test_image_dir = f\"{base_path}/images/offsite_test\"\n",
        "pretrained_resnet = f\"{base_path}/checkpoints/resnet18_DLsns_task1-3.pt\"\n",
        "\n",
        "# ====================================================================\n",
        "# TASK 2.1: FOCAL LOSS\n",
        "# ====================================================================\n",
        "print(\"\\n TASK 2.1: Focal Loss\\n\")\n",
        "\n",
        "focal_loss = FocalLoss(alpha=0.75, gamma=2.5)\n",
        "\n",
        "ckpt_focal, test_loader = train_task2(\n",
        "    backbone='resnet18',\n",
        "    loss_fn=focal_loss,\n",
        "    loss_name='focal_loss',\n",
        "    train_csv=train_csv,\n",
        "    val_csv=val_csv,\n",
        "    test_csv=test_csv,\n",
        "    train_image_dir=train_image_dir,\n",
        "    val_image_dir=val_image_dir,\n",
        "    test_image_dir=test_image_dir,\n",
        "    pretrained_backbone=pretrained_resnet,\n",
        "    epochs=60,\n",
        "    batch_size=12,\n",
        "    lr=2e-5\n",
        ")\n",
        "\n",
        "results_focal = evaluate_task2(ckpt_focal, 'resnet18', test_loader)\n",
        "\n",
        "\n",
        "onsite_csv = f\"{base_path}/onsite_test_submission.csv\"\n",
        "onsite_image_dir = f\"{base_path}/images/onsite_test\"\n",
        "\n",
        "submission_focal = generate_submission(ckpt_focal, 'resnet18', onsite_csv,\n",
        "                                      onsite_image_dir, \"task2_1_focal_loss.csv\")\n",
        "\n",
        "print(f\" Task 2.1 (Focal Loss) - Offsite: {results_focal['average_f1']*100:.2f}%\")\n",
        "print(\" Download: task2_1_focal_loss.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxuqZDTdr8ag",
        "outputId": "4b140c31-bd6e-41c2-85bf-8db284b41258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TASK 2.1: Focal Loss\n",
            "\n",
            " Train: 800, Val: 200, Test: 200\n",
            "\n",
            "======================================================================\n",
            " TASK 2: resnet18 + focal_loss\n",
            "======================================================================\n",
            "\n",
            "E01/60 | Train:0.0987 | Val:0.0865 | F1:0.3505\n",
            "   BEST! F1: 0.3505\n",
            "E02/60 | Train:0.0765 | Val:0.0525 | F1:0.6173\n",
            "   BEST! F1: 0.6173\n",
            "E03/60 | Train:0.0523 | Val:0.0333 | F1:0.6936\n",
            "   BEST! F1: 0.6936\n",
            "E04/60 | Train:0.0395 | Val:0.0355 | F1:0.7294\n",
            "   BEST! F1: 0.7294\n",
            "E05/60 | Train:0.0408 | Val:0.0436 | F1:0.7271\n",
            "E06/60 | Train:0.0382 | Val:0.0370 | F1:0.7479\n",
            "   BEST! F1: 0.7479\n",
            "E07/60 | Train:0.0373 | Val:0.0355 | F1:0.7571\n",
            "   BEST! F1: 0.7571\n",
            "E08/60 | Train:0.0381 | Val:0.0350 | F1:0.7602\n",
            "   BEST! F1: 0.7602\n",
            "E09/60 | Train:0.0366 | Val:0.0351 | F1:0.7556\n",
            "E10/60 | Train:0.0325 | Val:0.0337 | F1:0.7749\n",
            "   BEST! F1: 0.7749\n",
            "E11/60 | Train:0.0328 | Val:0.0420 | F1:0.7461\n",
            "E12/60 | Train:0.0354 | Val:0.0360 | F1:0.7662\n",
            "E13/60 | Train:0.0330 | Val:0.0383 | F1:0.7490\n",
            "E14/60 | Train:0.0330 | Val:0.0334 | F1:0.7888\n",
            "   BEST! F1: 0.7888\n",
            "E15/60 | Train:0.0307 | Val:0.0348 | F1:0.7467\n",
            "E16/60 | Train:0.0295 | Val:0.0315 | F1:0.7790\n",
            "E17/60 | Train:0.0273 | Val:0.0428 | F1:0.7306\n",
            "E18/60 | Train:0.0294 | Val:0.0348 | F1:0.7638\n",
            "E19/60 | Train:0.0278 | Val:0.0414 | F1:0.7691\n",
            "E20/60 | Train:0.0292 | Val:0.0326 | F1:0.7642\n",
            "E21/60 | Train:0.0273 | Val:0.0407 | F1:0.7612\n",
            "E22/60 | Train:0.0296 | Val:0.0382 | F1:0.7842\n",
            "E23/60 | Train:0.0266 | Val:0.0330 | F1:0.7746\n",
            "E24/60 | Train:0.0255 | Val:0.0333 | F1:0.7842\n",
            "E25/60 | Train:0.0268 | Val:0.0356 | F1:0.7823\n",
            "E26/60 | Train:0.0250 | Val:0.0412 | F1:0.7889\n",
            "   BEST! F1: 0.7889\n",
            "E27/60 | Train:0.0243 | Val:0.0419 | F1:0.7677\n",
            "E28/60 | Train:0.0248 | Val:0.0413 | F1:0.7836\n",
            "E29/60 | Train:0.0236 | Val:0.0501 | F1:0.7683\n",
            "E30/60 | Train:0.0224 | Val:0.0428 | F1:0.7702\n",
            "E31/60 | Train:0.0228 | Val:0.0481 | F1:0.7976\n",
            "   BEST! F1: 0.7976\n",
            "E32/60 | Train:0.0244 | Val:0.0423 | F1:0.8063\n",
            "   BEST! F1: 0.8063\n",
            "E33/60 | Train:0.0240 | Val:0.0372 | F1:0.8011\n",
            "E34/60 | Train:0.0252 | Val:0.0390 | F1:0.7945\n",
            "E35/60 | Train:0.0214 | Val:0.0419 | F1:0.8078\n",
            "   BEST! F1: 0.8078\n",
            "E36/60 | Train:0.0221 | Val:0.0388 | F1:0.7902\n",
            "E37/60 | Train:0.0223 | Val:0.0374 | F1:0.7945\n",
            "E38/60 | Train:0.0217 | Val:0.0465 | F1:0.8009\n",
            "E39/60 | Train:0.0215 | Val:0.0430 | F1:0.8022\n",
            "E40/60 | Train:0.0215 | Val:0.0396 | F1:0.7989\n",
            "E41/60 | Train:0.0179 | Val:0.0382 | F1:0.7967\n",
            "E42/60 | Train:0.0211 | Val:0.0374 | F1:0.8121\n",
            "   BEST! F1: 0.8121\n",
            "E43/60 | Train:0.0210 | Val:0.0402 | F1:0.7993\n",
            "E44/60 | Train:0.0204 | Val:0.0382 | F1:0.7933\n",
            "E45/60 | Train:0.0228 | Val:0.0373 | F1:0.7953\n",
            "E46/60 | Train:0.0195 | Val:0.0383 | F1:0.7976\n",
            "E47/60 | Train:0.0179 | Val:0.0421 | F1:0.8055\n",
            "E48/60 | Train:0.0209 | Val:0.0403 | F1:0.7991\n",
            "E49/60 | Train:0.0211 | Val:0.0393 | F1:0.7995\n",
            "E50/60 | Train:0.0200 | Val:0.0430 | F1:0.7985\n",
            "E51/60 | Train:0.0190 | Val:0.0392 | F1:0.8023\n",
            "E52/60 | Train:0.0174 | Val:0.0392 | F1:0.8006\n",
            "E53/60 | Train:0.0168 | Val:0.0388 | F1:0.8114\n",
            "E54/60 | Train:0.0197 | Val:0.0402 | F1:0.8054\n",
            "E55/60 | Train:0.0188 | Val:0.0405 | F1:0.7982\n",
            "E56/60 | Train:0.0202 | Val:0.0397 | F1:0.8002\n",
            "E57/60 | Train:0.0200 | Val:0.0400 | F1:0.8037\n",
            "E58/60 | Train:0.0190 | Val:0.0391 | F1:0.8078\n",
            "E59/60 | Train:0.0192 | Val:0.0412 | F1:0.8027\n",
            "E60/60 | Train:0.0187 | Val:0.0393 | F1:0.7999\n",
            "\n",
            " Complete! Best Val F1: 0.8121\n",
            "\n",
            "\n",
            "======================================================================\n",
            " OFFSITE TEST EVALUATION\n",
            "======================================================================\n",
            "Disease         Precision    Recall       F1-Score    \n",
            "----------------------------------------------------------------------\n",
            "DR              0.8581       0.9500       0.9017      \n",
            "Glaucoma        0.8222       0.7551       0.7872      \n",
            "AMD             0.4286       0.6818       0.5263      \n",
            "----------------------------------------------------------------------\n",
            "AVG F1:         0.7384 (73.84%)\n",
            "======================================================================\n",
            "\n",
            " Saved: task2_1_focal_loss.csv\n",
            "\n",
            " Task 2.1 (Focal Loss) - Offsite: 73.84%\n",
            " Download: task2_1_focal_loss.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# TASK 2.2: CLASS-BALANCED LOSS\n",
        "# ====================================================================\n",
        "print(\"\\n TASK 2.2: Class-Balanced Loss\\n\")\n",
        "\n",
        "samples_per_class = [537, 163, 142]\n",
        "cb_loss = ClassBalancedLoss(samples_per_class=samples_per_class, beta=0.9999)\n",
        "\n",
        "ckpt_cb, test_loader = train_task2(\n",
        "    backbone='resnet18',\n",
        "    loss_fn=cb_loss,\n",
        "    loss_name='class_balanced',\n",
        "    train_csv=train_csv,\n",
        "    val_csv=val_csv,\n",
        "    test_csv=test_csv,\n",
        "    train_image_dir=train_image_dir,\n",
        "    val_image_dir=val_image_dir,\n",
        "    test_image_dir=test_image_dir,\n",
        "    pretrained_backbone=pretrained_resnet,\n",
        "    epochs=60,\n",
        "    batch_size=12,\n",
        "    lr=2e-5\n",
        ")\n",
        "\n",
        "results_cb = evaluate_task2(ckpt_cb, 'resnet18', test_loader)\n",
        "\n",
        "submission_cb = generate_submission(ckpt_cb, 'resnet18', onsite_csv,\n",
        "                                   onsite_image_dir, \"task2_2_class_balanced.csv\")\n",
        "\n",
        "print(f\" Task 2.2 (Class-Balanced) - Offsite: {results_cb['average_f1']*100:.2f}%\")\n",
        "print(\" Download: task2_2_class_balanced.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G40EjccnsD_X",
        "outputId": "4abdeb81-3d7f-4fd2-8581-67d4f0d88536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TASK 2.2: Class-Balanced Loss\n",
            "\n",
            " Train: 800, Val: 200, Test: 200\n",
            "\n",
            "======================================================================\n",
            " TASK 2: resnet18 + class_balanced\n",
            "======================================================================\n",
            "\n",
            "E01/60 | Train:0.7265 | Val:0.6862 | F1:0.2034\n",
            "   BEST! F1: 0.2034\n",
            "E02/60 | Train:0.6336 | Val:0.5406 | F1:0.4162\n",
            "   BEST! F1: 0.4162\n",
            "E03/60 | Train:0.5011 | Val:0.4278 | F1:0.6763\n",
            "   BEST! F1: 0.6763\n",
            "E04/60 | Train:0.3782 | Val:0.3493 | F1:0.7296\n",
            "   BEST! F1: 0.7296\n",
            "E05/60 | Train:0.3265 | Val:0.3374 | F1:0.7356\n",
            "   BEST! F1: 0.7356\n",
            "E06/60 | Train:0.3190 | Val:0.3266 | F1:0.7492\n",
            "   BEST! F1: 0.7492\n",
            "E07/60 | Train:0.3212 | Val:0.4176 | F1:0.6682\n",
            "E08/60 | Train:0.3208 | Val:0.3523 | F1:0.7205\n",
            "E09/60 | Train:0.2969 | Val:0.4221 | F1:0.6783\n",
            "E10/60 | Train:0.3040 | Val:0.3635 | F1:0.7309\n",
            "E11/60 | Train:0.2821 | Val:0.3245 | F1:0.7461\n",
            "E12/60 | Train:0.2681 | Val:0.3601 | F1:0.7220\n",
            "E13/60 | Train:0.2799 | Val:0.3866 | F1:0.7301\n",
            "E14/60 | Train:0.2774 | Val:0.3475 | F1:0.7763\n",
            "   BEST! F1: 0.7763\n",
            "E15/60 | Train:0.2645 | Val:0.3713 | F1:0.7575\n",
            "E16/60 | Train:0.2336 | Val:0.3251 | F1:0.8020\n",
            "   BEST! F1: 0.8020\n",
            "E17/60 | Train:0.2602 | Val:0.3460 | F1:0.7585\n",
            "E18/60 | Train:0.2646 | Val:0.3435 | F1:0.7585\n",
            "E19/60 | Train:0.2358 | Val:0.3400 | F1:0.7544\n",
            "E20/60 | Train:0.2502 | Val:0.3531 | F1:0.7603\n",
            "E21/60 | Train:0.2539 | Val:0.3406 | F1:0.7636\n",
            "E22/60 | Train:0.2491 | Val:0.3245 | F1:0.7433\n",
            "E23/60 | Train:0.2274 | Val:0.3443 | F1:0.7523\n",
            "E24/60 | Train:0.2207 | Val:0.3416 | F1:0.7854\n",
            "E25/60 | Train:0.2454 | Val:0.3456 | F1:0.7610\n",
            "E26/60 | Train:0.2246 | Val:0.3405 | F1:0.7694\n",
            "E27/60 | Train:0.2255 | Val:0.3318 | F1:0.7778\n",
            "E28/60 | Train:0.2027 | Val:0.3524 | F1:0.7877\n",
            "E29/60 | Train:0.2282 | Val:0.3328 | F1:0.7672\n",
            "E30/60 | Train:0.2304 | Val:0.3515 | F1:0.7783\n",
            "E31/60 | Train:0.2157 | Val:0.3565 | F1:0.7714\n",
            "E32/60 | Train:0.2106 | Val:0.3216 | F1:0.7947\n",
            "E33/60 | Train:0.1848 | Val:0.3591 | F1:0.7572\n",
            "E34/60 | Train:0.2198 | Val:0.3278 | F1:0.7838\n",
            "E35/60 | Train:0.2137 | Val:0.3169 | F1:0.7729\n",
            "E36/60 | Train:0.1974 | Val:0.3367 | F1:0.7886\n",
            "\n",
            " Early stop at epoch 36\n",
            "\n",
            " Complete! Best Val F1: 0.8020\n",
            "\n",
            "\n",
            "======================================================================\n",
            " OFFSITE TEST EVALUATION\n",
            "======================================================================\n",
            "Disease         Precision    Recall       F1-Score    \n",
            "----------------------------------------------------------------------\n",
            "DR              0.9380       0.8643       0.8996      \n",
            "Glaucoma        0.8478       0.7959       0.8211      \n",
            "AMD             0.6667       0.6364       0.6512      \n",
            "----------------------------------------------------------------------\n",
            "AVG F1:         0.7906 (79.06%)\n",
            "======================================================================\n",
            "\n",
            " Saved: task2_2_class_balanced.csv\n",
            "\n",
            " Task 2.2 (Class-Balanced) - Offsite: 79.06%\n",
            " Download: task2_2_class_balanced.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# TASK 2.1: EFFICIENTNET + FOCAL LOSS\n",
        "# ====================================================================\n",
        "print(\"\\n TASK 2.1: EfficientNet + Focal Loss\\n\")\n",
        "\n",
        "pretrained_eff = f\"{base_path}/checkpoints/efficientnet_DLsns_task1-3.pt\"\n",
        "focal_loss = FocalLoss(alpha=0.75, gamma=2.5)\n",
        "\n",
        "ckpt_focal_eff, test_loader_eff = train_task2(\n",
        "    backbone='efficientnet',\n",
        "    loss_fn=focal_loss,\n",
        "    loss_name='focal_loss',\n",
        "    train_csv=train_csv,\n",
        "    val_csv=val_csv,\n",
        "    test_csv=test_csv,\n",
        "    train_image_dir=train_image_dir,\n",
        "    val_image_dir=val_image_dir,\n",
        "    test_image_dir=test_image_dir,\n",
        "    pretrained_backbone=pretrained_eff,\n",
        "    epochs=60,\n",
        "    batch_size=12,\n",
        "    lr=2e-5  # Same LR as ResNet\n",
        ")\n",
        "\n",
        "results_focal_eff = evaluate_task2(ckpt_focal_eff, 'efficientnet', test_loader_eff)\n",
        "\n",
        "submission_focal_eff = generate_submission(ckpt_focal_eff, 'efficientnet', onsite_csv,\n",
        "                                          onsite_image_dir, \"task2_1_focal_efficientnet.csv\")\n",
        "\n",
        "print(f\" Task 2.1 EfficientNet (Focal) - Offsite: {results_focal_eff['average_f1']*100:.2f}%\")\n",
        "print(\" Download: task2_1_focal_efficientnet.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE489DUysOau",
        "outputId": "55b526d9-2c1f-4d55-aff7-2836aa7bc4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TASK 2.1: EfficientNet + Focal Loss\n",
            "\n",
            " Train: 800, Val: 200, Test: 200\n",
            "\n",
            "======================================================================\n",
            " TASK 2: efficientnet + focal_loss\n",
            "======================================================================\n",
            "\n",
            "E01/60 | Train:0.2212 | Val:0.5144 | F1:0.7298\n",
            "   BEST! F1: 0.7298\n",
            "E02/60 | Train:0.2226 | Val:0.5690 | F1:0.7265\n",
            "E03/60 | Train:0.2049 | Val:0.4882 | F1:0.7269\n",
            "E04/60 | Train:0.1800 | Val:0.4734 | F1:0.7564\n",
            "   BEST! F1: 0.7564\n",
            "E05/60 | Train:0.1161 | Val:0.4285 | F1:0.7564\n",
            "   BEST! F1: 0.7564\n",
            "E06/60 | Train:0.1062 | Val:0.3472 | F1:0.7485\n",
            "E07/60 | Train:0.0852 | Val:0.3180 | F1:0.7659\n",
            "   BEST! F1: 0.7659\n",
            "E08/60 | Train:0.0690 | Val:0.2718 | F1:0.7731\n",
            "   BEST! F1: 0.7731\n",
            "E09/60 | Train:0.0492 | Val:0.2545 | F1:0.7633\n",
            "E10/60 | Train:0.0507 | Val:0.2061 | F1:0.7858\n",
            "   BEST! F1: 0.7858\n",
            "E11/60 | Train:0.0501 | Val:0.1556 | F1:0.7873\n",
            "   BEST! F1: 0.7873\n",
            "E12/60 | Train:0.0328 | Val:0.1923 | F1:0.7796\n",
            "E13/60 | Train:0.0376 | Val:0.1767 | F1:0.7840\n",
            "E14/60 | Train:0.0272 | Val:0.1745 | F1:0.7796\n",
            "E15/60 | Train:0.0326 | Val:0.1346 | F1:0.7946\n",
            "   BEST! F1: 0.7946\n",
            "E16/60 | Train:0.0248 | Val:0.1334 | F1:0.7733\n",
            "E17/60 | Train:0.0235 | Val:0.1258 | F1:0.7806\n",
            "E18/60 | Train:0.0231 | Val:0.1135 | F1:0.7877\n",
            "E19/60 | Train:0.0266 | Val:0.1340 | F1:0.7696\n",
            "E20/60 | Train:0.0233 | Val:0.1061 | F1:0.7784\n",
            "E21/60 | Train:0.0249 | Val:0.1022 | F1:0.7818\n",
            "E22/60 | Train:0.0237 | Val:0.0925 | F1:0.7704\n",
            "E23/60 | Train:0.0212 | Val:0.0820 | F1:0.7820\n",
            "E24/60 | Train:0.0203 | Val:0.0866 | F1:0.7836\n",
            "E25/60 | Train:0.0201 | Val:0.0877 | F1:0.7655\n",
            "E26/60 | Train:0.0199 | Val:0.0883 | F1:0.7811\n",
            "E27/60 | Train:0.0191 | Val:0.0784 | F1:0.7776\n",
            "E28/60 | Train:0.0217 | Val:0.0963 | F1:0.7736\n",
            "E29/60 | Train:0.0199 | Val:0.0738 | F1:0.7908\n",
            "E30/60 | Train:0.0201 | Val:0.0690 | F1:0.7742\n",
            "E31/60 | Train:0.0186 | Val:0.0759 | F1:0.7903\n",
            "E32/60 | Train:0.0184 | Val:0.0652 | F1:0.7973\n",
            "   BEST! F1: 0.7973\n",
            "E33/60 | Train:0.0170 | Val:0.0727 | F1:0.7873\n",
            "E34/60 | Train:0.0157 | Val:0.0757 | F1:0.7900\n",
            "E35/60 | Train:0.0200 | Val:0.0855 | F1:0.7804\n",
            "E36/60 | Train:0.0169 | Val:0.0781 | F1:0.7744\n",
            "E37/60 | Train:0.0173 | Val:0.0719 | F1:0.7865\n",
            "E38/60 | Train:0.0173 | Val:0.0722 | F1:0.7746\n",
            "E39/60 | Train:0.0171 | Val:0.0790 | F1:0.7789\n",
            "E40/60 | Train:0.0193 | Val:0.0757 | F1:0.7807\n",
            "E41/60 | Train:0.0166 | Val:0.0689 | F1:0.7929\n",
            "E42/60 | Train:0.0188 | Val:0.0604 | F1:0.7943\n",
            "E43/60 | Train:0.0162 | Val:0.0583 | F1:0.7975\n",
            "   BEST! F1: 0.7975\n",
            "E44/60 | Train:0.0169 | Val:0.0638 | F1:0.7818\n",
            "E45/60 | Train:0.0182 | Val:0.0771 | F1:0.7771\n",
            "E46/60 | Train:0.0170 | Val:0.0622 | F1:0.7928\n",
            "E47/60 | Train:0.0165 | Val:0.0666 | F1:0.7838\n",
            "E48/60 | Train:0.0175 | Val:0.0701 | F1:0.7839\n",
            "E49/60 | Train:0.0154 | Val:0.0644 | F1:0.7760\n",
            "E50/60 | Train:0.0176 | Val:0.0753 | F1:0.7766\n",
            "E51/60 | Train:0.0168 | Val:0.0679 | F1:0.7879\n",
            "E52/60 | Train:0.0182 | Val:0.0684 | F1:0.7823\n",
            "E53/60 | Train:0.0159 | Val:0.0640 | F1:0.7917\n",
            "E54/60 | Train:0.0143 | Val:0.0711 | F1:0.7854\n",
            "E55/60 | Train:0.0172 | Val:0.0725 | F1:0.7843\n",
            "E56/60 | Train:0.0163 | Val:0.0626 | F1:0.7967\n",
            "E57/60 | Train:0.0161 | Val:0.0631 | F1:0.7877\n",
            "E58/60 | Train:0.0180 | Val:0.0680 | F1:0.7795\n",
            "E59/60 | Train:0.0156 | Val:0.0600 | F1:0.7781\n",
            "E60/60 | Train:0.0157 | Val:0.0674 | F1:0.7814\n",
            "\n",
            " Complete! Best Val F1: 0.7975\n",
            "\n",
            "\n",
            "======================================================================\n",
            " OFFSITE TEST EVALUATION\n",
            "======================================================================\n",
            "Disease         Precision    Recall       F1-Score    \n",
            "----------------------------------------------------------------------\n",
            "DR              0.8477       0.9143       0.8797      \n",
            "Glaucoma        0.6897       0.8163       0.7477      \n",
            "AMD             0.5333       0.7273       0.6154      \n",
            "----------------------------------------------------------------------\n",
            "AVG F1:         0.7476 (74.76%)\n",
            "======================================================================\n",
            "\n",
            " Saved: task2_1_focal_efficientnet.csv\n",
            "\n",
            " Task 2.1 EfficientNet (Focal) - Offsite: 74.76%\n",
            " Download: task2_1_focal_efficientnet.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# TASK 2.2: EFFICIENTNET + CLASS-BALANCED LOSS\n",
        "# ====================================================================\n",
        "print(\"\\n TASK 2.2: EfficientNet + Class-Balanced Loss\\n\")\n",
        "\n",
        "samples_per_class = [537, 163, 142]\n",
        "cb_loss = ClassBalancedLoss(samples_per_class=samples_per_class, beta=0.9999)\n",
        "\n",
        "ckpt_cb_eff, test_loader_eff = train_task2(\n",
        "    backbone='efficientnet',\n",
        "    loss_fn=cb_loss,\n",
        "    loss_name='class_balanced',\n",
        "    train_csv=train_csv,\n",
        "    val_csv=val_csv,\n",
        "    test_csv=test_csv,\n",
        "    train_image_dir=train_image_dir,\n",
        "    val_image_dir=val_image_dir,\n",
        "    test_image_dir=test_image_dir,\n",
        "    pretrained_backbone=pretrained_eff,\n",
        "    epochs=60,\n",
        "    batch_size=12,\n",
        "    lr=2e-5\n",
        ")\n",
        "\n",
        "results_cb_eff = evaluate_task2(ckpt_cb_eff, 'efficientnet', test_loader_eff)\n",
        "\n",
        "submission_cb_eff = generate_submission(ckpt_cb_eff, 'efficientnet', onsite_csv,\n",
        "                                       onsite_image_dir, \"task2_2_class_balanced_efficientnet.csv\")\n",
        "\n",
        "print(f\" Task 2.2 EfficientNet (Class-Balanced) - Offsite: {results_cb_eff['average_f1']*100:.2f}%\")\n",
        "print(\" Download: task2_2_class_balanced_efficientnet.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itmDT4Q8smh7",
        "outputId": "2666d8ad-79f7-4fbd-b1a1-4abbc25e27a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TASK 2.2: EfficientNet + Class-Balanced Loss\n",
            "\n",
            " Train: 800, Val: 200, Test: 200\n",
            "\n",
            "======================================================================\n",
            " TASK 2: efficientnet + class_balanced\n",
            "======================================================================\n",
            "\n",
            "E01/60 | Train:0.5113 | Val:0.8627 | F1:0.7241\n",
            "   BEST! F1: 0.7241\n",
            "E02/60 | Train:0.4337 | Val:0.9031 | F1:0.7371\n",
            "   BEST! F1: 0.7371\n",
            "E03/60 | Train:0.4019 | Val:0.8470 | F1:0.7431\n",
            "   BEST! F1: 0.7431\n",
            "E04/60 | Train:0.3765 | Val:0.7965 | F1:0.7423\n",
            "E05/60 | Train:0.3476 | Val:0.7527 | F1:0.7530\n",
            "   BEST! F1: 0.7530\n",
            "E06/60 | Train:0.3234 | Val:0.6977 | F1:0.7637\n",
            "   BEST! F1: 0.7637\n",
            "E07/60 | Train:0.2805 | Val:0.6638 | F1:0.7607\n",
            "E08/60 | Train:0.2727 | Val:0.6121 | F1:0.7795\n",
            "   BEST! F1: 0.7795\n",
            "E09/60 | Train:0.2354 | Val:0.6310 | F1:0.7761\n",
            "E10/60 | Train:0.2580 | Val:0.5861 | F1:0.7578\n",
            "E11/60 | Train:0.2323 | Val:0.5551 | F1:0.7632\n",
            "E12/60 | Train:0.2435 | Val:0.5015 | F1:0.7942\n",
            "   BEST! F1: 0.7942\n",
            "E13/60 | Train:0.2303 | Val:0.5482 | F1:0.7793\n",
            "E14/60 | Train:0.2094 | Val:0.4660 | F1:0.7863\n",
            "E15/60 | Train:0.1981 | Val:0.5261 | F1:0.7762\n",
            "E16/60 | Train:0.1912 | Val:0.4822 | F1:0.7910\n",
            "E17/60 | Train:0.1905 | Val:0.4926 | F1:0.8019\n",
            "   BEST! F1: 0.8019\n",
            "E18/60 | Train:0.1717 | Val:0.5160 | F1:0.7678\n",
            "E19/60 | Train:0.1897 | Val:0.5134 | F1:0.7730\n",
            "E20/60 | Train:0.1868 | Val:0.5050 | F1:0.7894\n",
            "E21/60 | Train:0.1872 | Val:0.4874 | F1:0.7799\n",
            "E22/60 | Train:0.1680 | Val:0.5419 | F1:0.7687\n",
            "E23/60 | Train:0.1744 | Val:0.5261 | F1:0.7893\n",
            "E24/60 | Train:0.1942 | Val:0.5093 | F1:0.7869\n",
            "E25/60 | Train:0.1752 | Val:0.4674 | F1:0.8154\n",
            "   BEST! F1: 0.8154\n",
            "E26/60 | Train:0.1579 | Val:0.5700 | F1:0.7813\n",
            "E27/60 | Train:0.1416 | Val:0.5221 | F1:0.7899\n",
            "E28/60 | Train:0.1825 | Val:0.4867 | F1:0.7894\n",
            "E29/60 | Train:0.1815 | Val:0.5054 | F1:0.7953\n",
            "E30/60 | Train:0.1779 | Val:0.4899 | F1:0.7910\n",
            "E31/60 | Train:0.1634 | Val:0.5015 | F1:0.7993\n",
            "E32/60 | Train:0.1682 | Val:0.5270 | F1:0.7891\n",
            "E33/60 | Train:0.1592 | Val:0.5284 | F1:0.8005\n",
            "E34/60 | Train:0.1337 | Val:0.4731 | F1:0.7982\n",
            "E35/60 | Train:0.1564 | Val:0.5310 | F1:0.7806\n",
            "E36/60 | Train:0.1356 | Val:0.5124 | F1:0.7977\n",
            "E37/60 | Train:0.1761 | Val:0.5392 | F1:0.7911\n",
            "E38/60 | Train:0.1643 | Val:0.5119 | F1:0.7791\n",
            "E39/60 | Train:0.1393 | Val:0.4901 | F1:0.7963\n",
            "E40/60 | Train:0.1461 | Val:0.4655 | F1:0.7963\n",
            "E41/60 | Train:0.1639 | Val:0.4758 | F1:0.7941\n",
            "E42/60 | Train:0.1084 | Val:0.4839 | F1:0.7927\n",
            "E43/60 | Train:0.1575 | Val:0.5586 | F1:0.7881\n",
            "E44/60 | Train:0.1426 | Val:0.4739 | F1:0.7815\n",
            "E45/60 | Train:0.1494 | Val:0.4836 | F1:0.7857\n",
            "\n",
            " Early stop at epoch 45\n",
            "\n",
            " Complete! Best Val F1: 0.8154\n",
            "\n",
            "\n",
            "======================================================================\n",
            " OFFSITE TEST EVALUATION\n",
            "======================================================================\n",
            "Disease         Precision    Recall       F1-Score    \n",
            "----------------------------------------------------------------------\n",
            "DR              0.8750       0.8500       0.8623      \n",
            "Glaucoma        0.7826       0.7347       0.7579      \n",
            "AMD             0.5185       0.6364       0.5714      \n",
            "----------------------------------------------------------------------\n",
            "AVG F1:         0.7305 (73.05%)\n",
            "======================================================================\n",
            "\n",
            " Saved: task2_2_class_balanced_efficientnet.csv\n",
            "\n",
            " Task 2.2 EfficientNet (Class-Balanced) - Offsite: 73.05%\n",
            " Download: task2_2_class_balanced_efficientnet.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" COMPLETE TASK 2 RESULTS - ALL CONFIGURATIONS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nRESNET18:\")\n",
        "print(f\"  Task 2.1 - Focal Loss:        Offsite: {results_focal['average_f1']*100:.2f}%\")\n",
        "print(f\"  Task 2.2 - Class-Balanced:    Offsite: {results_cb['average_f1']*100:.2f}%\")\n",
        "print(\"\\nEFFICIENTNET:\")\n",
        "print(f\"  Task 2.1 - Focal Loss:        Offsite: {results_focal_eff['average_f1']*100:.2f}%\")\n",
        "print(f\"  Task 2.2 - Class-Balanced:    Offsite: {results_cb_eff['average_f1']*100:.2f}%\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T83kZd9esucB",
        "outputId": "d2692c2c-f59c-48d8-abfe-e928b614f562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " COMPLETE TASK 2 RESULTS - ALL CONFIGURATIONS\n",
            "================================================================================\n",
            "\n",
            "RESNET18:\n",
            "  Task 2.1 - Focal Loss:        Offsite: 73.84%\n",
            "  Task 2.2 - Class-Balanced:    Offsite: 79.06%\n",
            "\n",
            "EFFICIENTNET:\n",
            "  Task 2.1 - Focal Loss:        Offsite: 74.76%\n",
            "  Task 2.2 - Class-Balanced:    Offsite: 73.05%\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3"
      ],
      "metadata": {
        "id": "od3tvEYEpvxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzH0JnenqYXc",
        "outputId": "a44b7395-71f5-4f2c-cba8-7dbd4a7ca48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n"
      ],
      "metadata": {
        "id": "hQpcOBrWvBvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 3 - FINAL VERSION\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET CLASS\n",
        "# ============================================================================\n",
        "class RetinaMultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Validate dataset\n",
        "        valid_indices = []\n",
        "        for idx in range(len(self.data)):\n",
        "            row = self.data.iloc[idx]\n",
        "            img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "            if os.path.exists(img_path):\n",
        "                valid_indices.append(idx)\n",
        "\n",
        "        original_len = len(self.data)\n",
        "        self.data = self.data.iloc[valid_indices].reset_index(drop=True)\n",
        "\n",
        "        if len(self.data) < original_len:\n",
        "            print(f\" Warning: {original_len - len(self.data)} images missing\")\n",
        "        print(f\"Dataset ready: {len(self.data)} valid images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, labels\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TASK 3.1: SE BLOCK\n",
        "# ============================================================================\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Squeeze-and-Excitation Block - ORIGINAL VERSION\n",
        "    Reference: Hu et al., \"Squeeze-and-Excitation Networks\" (CVPR 2018)\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        reduced_channels = max(channels // reduction, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(channels, reduced_channels, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(reduced_channels, channels, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, _, _ = x.size()\n",
        "\n",
        "        squeeze = F.adaptive_avg_pool2d(x, 1).view(batch, channels)\n",
        "\n",
        "        excitation = self.fc1(squeeze)\n",
        "        excitation = self.relu(excitation)\n",
        "        excitation = self.fc2(excitation)\n",
        "        excitation = self.sigmoid(excitation)\n",
        "\n",
        "        # Scale\n",
        "        excitation = excitation.view(batch, channels, 1, 1)\n",
        "        return x * excitation.expand_as(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TASK 3.2: MHA BLOCK\n",
        "# ============================================================================\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Attention for Vision - IMPROVED VERSION\n",
        "    Reference: Vaswani et al., \"Attention is All You Need\" (NeurIPS 2017)\n",
        "\n",
        "    IMPROVEMENTS:\n",
        "    - Added dropout parameter (default=0.4)\n",
        "    - Dropout on attention weights\n",
        "    - Dropout on output projection\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, num_heads=8, reduction=4, dropout=0.4):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert channels % num_heads == 0, f\"channels must be divisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = channels // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.reduction = reduction\n",
        "\n",
        "        if reduction > 1:\n",
        "            self.pool = nn.AvgPool2d(kernel_size=reduction, stride=reduction)\n",
        "        else:\n",
        "            self.pool = nn.Identity()\n",
        "\n",
        "        self.qkv = nn.Linear(channels, channels * 3, bias=False)\n",
        "        self.proj_out = nn.Linear(channels, channels, bias=False)\n",
        "        self.norm = nn.LayerNorm(channels)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, H, W = x.size()\n",
        "        identity = x\n",
        "\n",
        "        # Spatial reduction\n",
        "        x_reduced = self.pool(x)\n",
        "        _, _, h, w = x_reduced.size()\n",
        "        seq_len = h * w\n",
        "\n",
        "        # Reshape to sequence\n",
        "        x_flat = x_reduced.flatten(2).transpose(1, 2)\n",
        "\n",
        "        # Generate Q, K, V\n",
        "        qkv = self.qkv(x_flat)\n",
        "        qkv = qkv.reshape(batch, seq_len, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        attn_scores = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "        attn_out = attn_weights @ v\n",
        "\n",
        "        # Concatenate heads\n",
        "        attn_out = attn_out.transpose(1, 2).contiguous()\n",
        "        attn_out = attn_out.reshape(batch, seq_len, channels)\n",
        "\n",
        "        # Output projection\n",
        "        out = self.proj_out(attn_out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.norm(out)\n",
        "\n",
        "        # Reshape back to spatial\n",
        "        out = out.transpose(1, 2).reshape(batch, channels, h, w)\n",
        "\n",
        "        # Upsample if needed\n",
        "        if self.reduction > 1:\n",
        "            out = F.interpolate(out, size=(H, W), mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Residual connection\n",
        "        return identity + out\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BUILD MODEL FUNCTION\n",
        "# ============================================================================\n",
        "def build_model_with_attention(backbone=\"resnet18\", num_classes=3, attention_type=None):\n",
        "    \"\"\"\n",
        "    Build model with attention mechanisms\n",
        "\n",
        "    Args:\n",
        "        backbone: 'resnet18' or 'efficientnet'\n",
        "        num_classes: 3 (DR, Glaucoma, AMD)\n",
        "        attention_type: 'se' or 'mha'\n",
        "    \"\"\"\n",
        "    if backbone == \"resnet18\":\n",
        "        model = models.resnet18(weights=None)\n",
        "        num_channels = 512\n",
        "\n",
        "        if attention_type == 'se':\n",
        "            original_layer4 = model.layer4\n",
        "            model.layer4 = nn.Sequential(\n",
        "                original_layer4,\n",
        "                SEBlock(num_channels, reduction=16)\n",
        "            )\n",
        "            print(f\" Inserted SE Block after layer4 ({num_channels} channels)\")\n",
        "\n",
        "        elif attention_type == 'mha':\n",
        "            original_layer4 = model.layer4\n",
        "            model.layer4 = nn.Sequential(\n",
        "                original_layer4,\n",
        "                MultiHeadAttention(num_channels, num_heads=8, reduction=2, dropout=0.4)\n",
        "            )\n",
        "            print(f\" Inserted MHA Block (IMPROVED with dropout) after layer4\")\n",
        "\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    elif backbone == \"efficientnet\":\n",
        "        model = models.efficientnet_b0(weights=None)\n",
        "        num_channels = 1280\n",
        "\n",
        "        if attention_type == 'se':\n",
        "            original_features = model.features\n",
        "            model.features = nn.Sequential(\n",
        "                original_features,\n",
        "                SEBlock(num_channels, reduction=16)\n",
        "            )\n",
        "            print(f\" Inserted SE Block (ORIGINAL)\")\n",
        "\n",
        "        elif attention_type == 'mha':\n",
        "            original_features = model.features\n",
        "            model.features = nn.Sequential(\n",
        "                original_features,\n",
        "                MultiHeadAttention(num_channels, num_heads=8, reduction=4, dropout=0.4)\n",
        "            )\n",
        "            print(f\" Inserted MHA Block (IMPROVED with dropout)\")\n",
        "\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported backbone\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TEST-TIME AUGMENTATION\n",
        "# ============================================================================\n",
        "def predict_with_tta(model, img, device):\n",
        "    \"\"\"Apply test-time augmentation for more robust predictions\"\"\"\n",
        "    model.eval()\n",
        "    transforms_tta = [\n",
        "        lambda x: x,\n",
        "        lambda x: torch.flip(x, dims=[3]),\n",
        "        lambda x: torch.flip(x, dims=[2]),\n",
        "    ]\n",
        "\n",
        "    probs_list = []\n",
        "    with torch.no_grad():\n",
        "        for transform in transforms_tta:\n",
        "            img_aug = transform(img)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(img_aug)\n",
        "                probs = torch.sigmoid(logits)\n",
        "            probs_list.append(probs)\n",
        "\n",
        "\n",
        "    return torch.stack(probs_list).mean(dim=0)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING FUNCTION\n",
        "# ============================================================================\n",
        "def train_task3(backbone, train_csv, val_csv,\n",
        "                offsite_test_csv, offsite_test_dir,\n",
        "                onsite_test_csv, onsite_test_dir,\n",
        "                train_image_dir, val_image_dir,\n",
        "                epochs=50, batch_size=12, lr=2e-5, img_size=256,\n",
        "                save_dir=\"./checkpoints\",\n",
        "                pretrained_task1_path=\"/content/drive/MyDrive/Colab Notebooks/final_project_resources/best_resnet18.pt\",\n",
        "                attention_type='se',\n",
        "                use_tta=True):\n",
        "    \"\"\"\n",
        "    Train Task 3 with attention mechanisms\n",
        "\n",
        "    TRAINING IMPROVEMENTS (applied to both SE and MHA):\n",
        "    - Strong augmentation (11 transforms)\n",
        "    - OneCycleLR scheduler\n",
        "    - Mixed precision training\n",
        "    - Gradient clipping\n",
        "    - F1-based model selection\n",
        "    - Early stopping\n",
        "    - Test-time augmentation\n",
        "    - AdamW optimizer\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TASK 3: Training {attention_type.upper()} Model\")\n",
        "    print(f\"  SE: ORIGINAL | MHA: IMPROVED (dropout)\")\n",
        "    print(f\"  Training: IMPROVED (for both)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Backbone: {backbone}\")\n",
        "    print(f\"Epochs: {epochs} | Batch: {batch_size} | LR: {lr}\")\n",
        "    print(f\"TTA: {'Enabled' if use_tta else 'Disabled'}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Strong augmentation\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((288, 288)),\n",
        "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
        "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.15),\n",
        "        transforms.RandomGrayscale(p=0.1),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "        transforms.RandomErasing(p=0.4, scale=(0.02, 0.2)),\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "    # Datasets\n",
        "    print(\"Loading datasets...\")\n",
        "    train_ds = RetinaMultiLabelDataset(train_csv, train_image_dir, train_transform)\n",
        "    val_ds = RetinaMultiLabelDataset(val_csv, val_image_dir, val_transform)\n",
        "    offsite_test_ds = RetinaMultiLabelDataset(offsite_test_csv, offsite_test_dir, val_transform)\n",
        "    onsite_test_ds = RetinaMultiLabelDataset(onsite_test_csv, onsite_test_dir, val_transform)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    offsite_test_loader = DataLoader(offsite_test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    onsite_test_loader = DataLoader(onsite_test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Build model\n",
        "    print(\"\\nBuilding model...\")\n",
        "    model = build_model_with_attention(\n",
        "        backbone=backbone,\n",
        "        num_classes=3,\n",
        "        attention_type=attention_type\n",
        "    ).to(device)\n",
        "\n",
        "    # Load Task 1 weights\n",
        "    print(f\"\\nLoading Task 1 pretrained weights...\")\n",
        "    try:\n",
        "        state_dict = torch.load(pretrained_task1_path, map_location=\"cpu\")\n",
        "        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "        if missing_keys:\n",
        "            print(f\" New layers initialized: {len(missing_keys)} layers\")\n",
        "        print(f\" Loaded pretrained backbone from Task 1\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not load pretrained weights: {e}\")\n",
        "        print(\"  Training from scratch...\")\n",
        "\n",
        "    # All parameters trainable\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # MHA-specific: Lower learning rate\n",
        "    if attention_type == 'mha':\n",
        "        lr = lr * 0.5\n",
        "        print(f\"\\n MHA-specific adjustment: Using lower LR = {lr}\")\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=lr * 3,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        pct_start=0.1\n",
        "    )\n",
        "\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    best_val_f1 = 0.0\n",
        "    patience = 0\n",
        "    max_patience = 20\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    attn_suffix = f\"_{attention_type}\" if attention_type else \"\"\n",
        "    ckpt_path = os.path.join(save_dir, f\"best_{backbone}_task3{attn_suffix}.pt\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Starting Training...\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed precision\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # Validation with F1 tracking\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    outputs = model(imgs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "                preds = (probs > 0.5).astype(int)\n",
        "                all_preds.append(preds)\n",
        "                all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        all_preds = np.concatenate(all_preds, axis=0)\n",
        "        all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "        # Calculate val F1\n",
        "        f1s = [f1_score(all_labels[:, i], all_preds[:, i], zero_division=0) for i in range(3)]\n",
        "        val_f1 = np.mean(f1s)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train {train_loss:.4f} | Val {val_loss:.4f} | F1 {val_f1:.4f}\")\n",
        "\n",
        "        # Save best based on F1\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            torch.save(model.state_dict(), ckpt_path)\n",
        "            print(f\"   Saved best model (F1={best_val_f1:.4f})\")\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= max_patience:\n",
        "                print(f\"  Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    print(f\"\\nBest Validation F1: {best_val_f1:.4f}\")\n",
        "\n",
        "    # OFFSITE Test Evaluation\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"OFFSITE Test Set Evaluation\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in offsite_test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                probs = predict_with_tta(model, imgs, device).cpu().numpy()\n",
        "            else:\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "            y_probs.extend(probs)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_probs = np.array(y_probs)\n",
        "\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "\n",
        "    print(f\"OFFSITE Test Results: {backbone.upper()} + {attention_type.upper()}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    f1_scores = []\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        acc = accuracy_score(y_t, y_p)\n",
        "        precision = precision_score(y_t, y_p, average=\"binary\", zero_division=0)\n",
        "        recall = recall_score(y_t, y_p, average=\"binary\", zero_division=0)\n",
        "        f1 = f1_score(y_t, y_p, average=\"binary\", zero_division=0)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        print(f\"{disease:12s} | Acc: {acc:.4f} | Prec: {precision:.4f} | Rec: {recall:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    avg_f1_offsite = np.mean(f1_scores)\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"OFFSITE Average F1: {avg_f1_offsite:.4f}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # ONSITE Test Predictions\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"ONSITE Test Predictions (for Kaggle)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    onsite_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in onsite_test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                probs = predict_with_tta(model, imgs, device).cpu().numpy()\n",
        "            else:\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            onsite_preds.extend(preds)\n",
        "\n",
        "    onsite_preds = np.array(onsite_preds)\n",
        "\n",
        "    # Save predictions\n",
        "    os.makedirs(\"./predictions\", exist_ok=True)\n",
        "    onsite_pred_filename = f\"task3_{backbone}{attn_suffix}_onsite_kaggle.csv\"\n",
        "    ids = pd.read_csv(onsite_test_csv)['id']\n",
        "    onsite_prediction = pd.DataFrame(onsite_preds, columns=['D', 'G', 'A'])\n",
        "    onsite_prediction.insert(0, 'id', ids)\n",
        "    onsite_prediction.to_csv(f\"./predictions/{onsite_pred_filename}\", index=False)\n",
        "    print(f\" Saved ONSITE predictions: ./predictions/{onsite_pred_filename}\")\n",
        "\n",
        "    offsite_pred_filename = f\"task3_{backbone}{attn_suffix}_offsite_results.csv\"\n",
        "    ids_offsite = pd.read_csv(offsite_test_csv)['id']\n",
        "    offsite_prediction = pd.DataFrame(y_pred, columns=['D', 'G', 'A'])\n",
        "    offsite_prediction.insert(0, 'id', ids_offsite)\n",
        "    offsite_prediction.to_csv(f\"./predictions/{offsite_pred_filename}\", index=False)\n",
        "    print(f\" Saved OFFSITE predictions: ./predictions/{offsite_pred_filename}\")\n",
        "\n",
        "    return model, avg_f1_offsite\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    base_path = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources\"\n",
        "\n",
        "    train_csv = f\"{base_path}/train.csv\"\n",
        "    val_csv = f\"{base_path}/val.csv\"\n",
        "    offsite_test_csv = f\"{base_path}/offsite_test.csv\"\n",
        "    offsite_test_dir = f\"{base_path}/images/offsite_test\"\n",
        "    onsite_test_csv = f\"{base_path}/onsite_test_submission.csv\"\n",
        "    onsite_test_dir = f\"{base_path}/images/onsite_test\"\n",
        "    train_image_dir = f\"{base_path}/images/train\"\n",
        "    val_image_dir = f\"{base_path}/images/val\"\n",
        "    pretrained_task1 = f\"{base_path}/best_resnet18.pt\"\n",
        "\n",
        "    backbone = 'resnet18'\n",
        "\n",
        "    # ========================================================================\n",
        "    # TASK 3.1: SE Block Model\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TASK 3.1: SE Block Model\")\n",
        "    print(\"  Architecture: ORIGINAL SE Block\")\n",
        "    print(\"  Training: IMPROVED\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model_se, f1_se = train_task3(\n",
        "        backbone=backbone,\n",
        "        train_csv=train_csv,\n",
        "        val_csv=val_csv,\n",
        "        offsite_test_csv=offsite_test_csv,\n",
        "        offsite_test_dir=offsite_test_dir,\n",
        "        onsite_test_csv=onsite_test_csv,\n",
        "        onsite_test_dir=onsite_test_dir,\n",
        "        train_image_dir=train_image_dir,\n",
        "        val_image_dir=val_image_dir,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        lr=1e-5,\n",
        "        img_size=256,\n",
        "        save_dir=f\"{base_path}/checkpoints\",\n",
        "        pretrained_task1_path=pretrained_task1,\n",
        "        attention_type='se',\n",
        "        use_tta=True\n",
        "    )\n",
        "\n",
        "    # ========================================================================\n",
        "    # TASK 3.2: MHA Model\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TASK 3.2: MHA Model\")\n",
        "    print(\"  Architecture: IMPROVED MHA (with dropout)\")\n",
        "    print(\"  Training: IMPROVED\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model_mha, f1_mha = train_task3(\n",
        "        backbone=backbone,\n",
        "        train_csv=train_csv,\n",
        "        val_csv=val_csv,\n",
        "        offsite_test_csv=offsite_test_csv,\n",
        "        offsite_test_dir=offsite_test_dir,\n",
        "        onsite_test_csv=onsite_test_csv,\n",
        "        onsite_test_dir=onsite_test_dir,\n",
        "        train_image_dir=train_image_dir,\n",
        "        val_image_dir=val_image_dir,\n",
        "        epochs=50,\n",
        "        batch_size=12,\n",
        "        lr=2e-5,\n",
        "        img_size=256,\n",
        "        save_dir=f\"{base_path}/checkpoints\",\n",
        "        pretrained_task1_path=pretrained_task1,\n",
        "        attention_type='mha',\n",
        "        use_tta=True\n",
        "    )\n",
        "\n",
        "    # ========================================================================\n",
        "    # FINAL SUMMARY\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TASK 3 COMPLETE - FINAL SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"SE Model  (ORIGINAL arch + IMPROVED training): Offsite F1 = {f1_se:.4f}\")\n",
        "    print(f\"MHA Model (IMPROVED arch + IMPROVED training): Offsite F1 = {f1_mha:.4f}\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nWhat was changed:\")\n",
        "    print(\"  SE Block:  NO changes (original architecture)\")\n",
        "    print(\"  MHA Block: IMPROVED with dropout (0.4)\")\n",
        "    print(\"  Training:  IMPROVED for both (augmentation, scheduler, etc.)\")\n",
        "    print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntDDZEgVvB3P",
        "outputId": "749989b9-ca75-4523-978a-80648b0b52de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TASK 3.1: Squeeze-and-Excitation (SE) Block\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TASK 3: Training with SE Attention\n",
            "Backbone: resnet18\n",
            "Loading Task 1 weights from: /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/resnet18_DLsns_task1-3.pt\n",
            "======================================================================\n",
            "\n",
            "\n",
            "Loading datasets...\n",
            "Dataset ready: 800 valid images\n",
            "Dataset ready: 200 valid images\n",
            "Dataset ready: 200 valid images\n",
            "Dataset ready: 250 valid images\n",
            "\n",
            "Building model...\n",
            " Inserted SE Block after layer4 (512 channels)\n",
            "\n",
            "Loading Task 1.3 weights...\n",
            " New layers (randomly initialized): 27 layers\n",
            " Loaded pretrained backbone and classifier from Task 1.3\n",
            "\n",
            "======================================================================\n",
            "Starting Training...\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/30 | Train Loss: 0.5295 | Val Loss: 0.5806\n",
            "   Saved best model\n",
            "Epoch 2/30 | Train Loss: 0.4794 | Val Loss: 0.5127\n",
            "   Saved best model\n",
            "Epoch 3/30 | Train Loss: 0.4296 | Val Loss: 0.4592\n",
            "   Saved best model\n",
            "Epoch 4/30 | Train Loss: 0.3928 | Val Loss: 0.4292\n",
            "   Saved best model\n",
            "Epoch 5/30 | Train Loss: 0.3565 | Val Loss: 0.4158\n",
            "   Saved best model\n",
            "Epoch 6/30 | Train Loss: 0.3364 | Val Loss: 0.4036\n",
            "   Saved best model\n",
            "Epoch 7/30 | Train Loss: 0.3103 | Val Loss: 0.3888\n",
            "   Saved best model\n",
            "Epoch 8/30 | Train Loss: 0.2881 | Val Loss: 0.3882\n",
            "   Saved best model\n",
            "Epoch 9/30 | Train Loss: 0.2706 | Val Loss: 0.3817\n",
            "   Saved best model\n",
            "Epoch 10/30 | Train Loss: 0.2602 | Val Loss: 0.3760\n",
            "   Saved best model\n",
            "Epoch 11/30 | Train Loss: 0.2445 | Val Loss: 0.3762\n",
            "Epoch 12/30 | Train Loss: 0.2470 | Val Loss: 0.3735\n",
            "   Saved best model\n",
            "Epoch 13/30 | Train Loss: 0.2308 | Val Loss: 0.3711\n",
            "   Saved best model\n",
            "Epoch 14/30 | Train Loss: 0.2200 | Val Loss: 0.3718\n",
            "Epoch 15/30 | Train Loss: 0.2141 | Val Loss: 0.3689\n",
            "   Saved best model\n",
            "Epoch 16/30 | Train Loss: 0.2072 | Val Loss: 0.3789\n",
            "Epoch 17/30 | Train Loss: 0.1966 | Val Loss: 0.3630\n",
            "   Saved best model\n",
            "Epoch 18/30 | Train Loss: 0.2007 | Val Loss: 0.3716\n",
            "Epoch 19/30 | Train Loss: 0.1902 | Val Loss: 0.3589\n",
            "   Saved best model\n",
            "Epoch 20/30 | Train Loss: 0.1777 | Val Loss: 0.3678\n",
            "Epoch 21/30 | Train Loss: 0.1776 | Val Loss: 0.3620\n",
            "Epoch 22/30 | Train Loss: 0.1771 | Val Loss: 0.3693\n",
            "Epoch 23/30 | Train Loss: 0.1663 | Val Loss: 0.3627\n",
            "Epoch 24/30 | Train Loss: 0.1697 | Val Loss: 0.3629\n",
            "Epoch 25/30 | Train Loss: 0.1552 | Val Loss: 0.3633\n",
            "Epoch 26/30 | Train Loss: 0.1620 | Val Loss: 0.3650\n",
            "Epoch 27/30 | Train Loss: 0.1569 | Val Loss: 0.3685\n",
            "Epoch 28/30 | Train Loss: 0.1484 | Val Loss: 0.3628\n",
            "Epoch 29/30 | Train Loss: 0.1596 | Val Loss: 0.3607\n",
            "Epoch 30/30 | Train Loss: 0.1480 | Val Loss: 0.3611\n",
            "\n",
            "======================================================================\n",
            "OFFSITE Test Set Evaluation (for Technical Report)\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "OFFSITE Test Results: RESNET18 with SE Attention\n",
            "======================================================================\n",
            "\n",
            "DR Results:\n",
            "  Accuracy : 0.8700\n",
            "  Precision: 0.9191\n",
            "  Recall   : 0.8929\n",
            "  F1-score : 0.9058\n",
            "\n",
            "Glaucoma Results:\n",
            "  Accuracy : 0.8900\n",
            "  Precision: 0.8140\n",
            "  Recall   : 0.7143\n",
            "  F1-score : 0.7609\n",
            "\n",
            "AMD Results:\n",
            "  Accuracy : 0.9550\n",
            "  Precision: 0.9333\n",
            "  Recall   : 0.6364\n",
            "  F1-score : 0.7568\n",
            "\n",
            "======================================================================\n",
            "OFFSITE Average F1-score: 0.8078\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ONSITE Test Set Predictions (for Kaggle Submission)\n",
            "======================================================================\n",
            "\n",
            " Saved ONSITE predictions for Kaggle: ./predictions/task3_resnet18_se_onsite_kaggle.csv\n",
            " Saved OFFSITE predictions: ./predictions/task3_resnet18_se_offsite_results.csv\n",
            "\n",
            "======================================================================\n",
            "Next Steps:\n",
            "======================================================================\n",
            "1. Submit task3_resnet18_se_onsite_kaggle.csv to Kaggle competition\n",
            "2. Get your average F-score from Kaggle\n",
            "3. Include OFFSITE metrics (above) in your technical report\n",
            "4. Include Kaggle F-score in your technical report\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TASK 3.2: Multi-Head Attention (MHA)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TASK 3: Training with MHA Attention\n",
            "Backbone: resnet18\n",
            "Loading Task 1 weights from: /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/resnet18_DLsns_task1-3.pt\n",
            "======================================================================\n",
            "\n",
            "\n",
            "Loading datasets...\n",
            "Dataset ready: 800 valid images\n",
            "Dataset ready: 200 valid images\n",
            "Dataset ready: 200 valid images\n",
            "Dataset ready: 250 valid images\n",
            "\n",
            "Building model...\n",
            " Inserted MHA Block after layer4 (512 channels)\n",
            "\n",
            "Loading Task 1.3 weights...\n",
            " New layers (randomly initialized): 29 layers\n",
            " Loaded pretrained backbone and classifier from Task 1.3\n",
            "\n",
            "======================================================================\n",
            "Starting Training...\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/30 | Train Loss: 0.5364 | Val Loss: 0.5791\n",
            "   Saved best model\n",
            "Epoch 2/30 | Train Loss: 0.4260 | Val Loss: 0.4610\n",
            "   Saved best model\n",
            "Epoch 3/30 | Train Loss: 0.3544 | Val Loss: 0.4104\n",
            "   Saved best model\n",
            "Epoch 4/30 | Train Loss: 0.2926 | Val Loss: 0.3967\n",
            "   Saved best model\n",
            "Epoch 5/30 | Train Loss: 0.2616 | Val Loss: 0.3934\n",
            "   Saved best model\n",
            "Epoch 6/30 | Train Loss: 0.2267 | Val Loss: 0.4114\n",
            "Epoch 7/30 | Train Loss: 0.2228 | Val Loss: 0.4039\n",
            "Epoch 8/30 | Train Loss: 0.2165 | Val Loss: 0.4097\n",
            "Epoch 9/30 | Train Loss: 0.1907 | Val Loss: 0.4045\n",
            "Epoch 10/30 | Train Loss: 0.1836 | Val Loss: 0.4179\n",
            "Epoch 11/30 | Train Loss: 0.1723 | Val Loss: 0.4006\n",
            "Epoch 12/30 | Train Loss: 0.1646 | Val Loss: 0.4027\n",
            "Epoch 13/30 | Train Loss: 0.1451 | Val Loss: 0.4162\n",
            "Epoch 14/30 | Train Loss: 0.1517 | Val Loss: 0.4155\n",
            "Epoch 15/30 | Train Loss: 0.1375 | Val Loss: 0.4228\n",
            "Epoch 16/30 | Train Loss: 0.1381 | Val Loss: 0.4302\n",
            "Epoch 17/30 | Train Loss: 0.1385 | Val Loss: 0.4250\n",
            "Epoch 18/30 | Train Loss: 0.1327 | Val Loss: 0.4370\n",
            "Epoch 19/30 | Train Loss: 0.1160 | Val Loss: 0.4430\n",
            "Epoch 20/30 | Train Loss: 0.1278 | Val Loss: 0.4361\n",
            "Epoch 21/30 | Train Loss: 0.1255 | Val Loss: 0.4420\n",
            "Epoch 22/30 | Train Loss: 0.1195 | Val Loss: 0.4488\n",
            "Epoch 23/30 | Train Loss: 0.1253 | Val Loss: 0.4435\n",
            "Epoch 24/30 | Train Loss: 0.1157 | Val Loss: 0.4441\n",
            "Epoch 25/30 | Train Loss: 0.1191 | Val Loss: 0.4508\n",
            "Epoch 26/30 | Train Loss: 0.1108 | Val Loss: 0.4457\n",
            "Epoch 27/30 | Train Loss: 0.1146 | Val Loss: 0.4458\n",
            "Epoch 28/30 | Train Loss: 0.1189 | Val Loss: 0.4524\n",
            "Epoch 29/30 | Train Loss: 0.1153 | Val Loss: 0.4429\n",
            "Epoch 30/30 | Train Loss: 0.1159 | Val Loss: 0.4523\n",
            "\n",
            "======================================================================\n",
            "OFFSITE Test Set Evaluation (for Technical Report)\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "OFFSITE Test Results: RESNET18 with MHA Attention\n",
            "======================================================================\n",
            "\n",
            "DR Results:\n",
            "  Accuracy : 0.8350\n",
            "  Precision: 0.8905\n",
            "  Recall   : 0.8714\n",
            "  F1-score : 0.8809\n",
            "\n",
            "Glaucoma Results:\n",
            "  Accuracy : 0.8800\n",
            "  Precision: 0.8049\n",
            "  Recall   : 0.6735\n",
            "  F1-score : 0.7333\n",
            "\n",
            "AMD Results:\n",
            "  Accuracy : 0.9300\n",
            "  Precision: 0.7222\n",
            "  Recall   : 0.5909\n",
            "  F1-score : 0.6500\n",
            "\n",
            "======================================================================\n",
            "OFFSITE Average F1-score: 0.7547\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ONSITE Test Set Predictions (for Kaggle Submission)\n",
            "======================================================================\n",
            "\n",
            " Saved ONSITE predictions for Kaggle: ./predictions/task3_resnet18_mha_onsite_kaggle.csv\n",
            " Saved OFFSITE predictions: ./predictions/task3_resnet18_mha_offsite_results.csv\n",
            "\n",
            "======================================================================\n",
            "Next Steps:\n",
            "======================================================================\n",
            "1. Submit task3_resnet18_mha_onsite_kaggle.csv to Kaggle competition\n",
            "2. Get your average F-score from Kaggle\n",
            "3. Include OFFSITE metrics (above) in your technical report\n",
            "4. Include Kaggle F-score in your technical report\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TASK 3 COMPLETE - FINAL SUMMARY\n",
            "======================================================================\n",
            "Task 3.1 (SE Block):  OFFSITE F1 = 0.8078\n",
            "Task 3.2 (MHA):       OFFSITE F1 = 0.7547\n",
            "======================================================================\n",
            "\n",
            "Files for submission:\n",
            "  Models:\n",
            "    - /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18_task3_se.pt\n",
            "    - /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/best_resnet18_task3_mha.pt\n",
            "  Kaggle submissions:\n",
            "    - ./predictions/task3_resnet18_se_onsite_kaggle.csv\n",
            "    - ./predictions/task3_resnet18_mha_onsite_kaggle.csv\n",
            "  Report analysis:\n",
            "    - ./predictions/task3_resnet18_se_offsite_results.csv\n",
            "    - ./predictions/task3_resnet18_mha_offsite_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4"
      ],
      "metadata": {
        "id": "YHO6LmnjjKIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ========================\n",
        "# build model\n",
        "# ========================\n",
        "def build_model(backbone=\"resnet18\", num_classes=3, pretrained=True):\n",
        "\n",
        "    if backbone == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif backbone == \"efficientnet\":\n",
        "        model = models.efficientnet_b0(pretrained=pretrained)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported backbone\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Task 4: Ensemble Learning (Weighted Average)\n",
        "# ==========================================\n",
        "def generate_ensemble_submission(resnet_ckpt, effnet_ckpt, test_csv, image_dir, output_file=\"ensemble_submission.csv\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Generating Ensemble from:\\n 1. {resnet_ckpt}\\n 2. {effnet_ckpt}\")\n",
        "\n",
        "    #Setup Data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "    test_df = pd.read_csv(test_csv)\n",
        "    dataset = RetinaMultiLabelDataset(test_csv, image_dir, transform)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Load Both Models\n",
        "    # Model 1: ResNet18, Model 2: EfficientNet\n",
        "    model_a = build_model(\"resnet18\", num_classes=3, pretrained=False).to(device)\n",
        "    model_a.load_state_dict(torch.load(resnet_ckpt, map_location=device))\n",
        "    model_a.eval()\n",
        "\n",
        "    model_b = build_model(\"efficientnet\", num_classes=3, pretrained=False).to(device)\n",
        "    model_b.load_state_dict(torch.load(effnet_ckpt, map_location=device))\n",
        "    model_b.eval()\n",
        "\n",
        "    # Predict and Average\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            out_a = model_a(imgs)\n",
        "            out_b = model_b(imgs)\n",
        "\n",
        "            prob_a = torch.sigmoid(out_a)\n",
        "            prob_b = torch.sigmoid(out_b)\n",
        "\n",
        "            avg_prob = (prob_a + prob_b) / 2.0\n",
        "\n",
        "            preds = (avg_prob > 0.5).int().cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    # Save Submission\n",
        "    submit_df = pd.DataFrame(all_preds, columns=['D', 'G', 'A'])\n",
        "    submit_df.insert(0, 'id', test_df.iloc[:, 0])\n",
        "    submit_df.to_csv(output_file, index=False)\n",
        "    print(f\" Ensemble submission saved to: {output_file}\")\n",
        "\n",
        "# ==========================================\n",
        "# Execution\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    base_path = \"/content/drive/MyDrive/Colab Notebooks/final_project_resources\" # replace with your own base path\n",
        "    resnet_pt = f\"{base_path}/checkpoints/resnet18_DLsns_task1-3.pt\" # replace with your own best Resnet18 model's path\n",
        "    effnet_pt = f\"{base_path}/checkpoints/efficientnet_DLsns_task1-3.pt\" # replace with your own best Efficientnet model's path\n",
        "    onsite_csv = f\"{base_path}/onsite_test_submission.csv\"  # replace with your own output result file's path\n",
        "    onsite_imgs = f\"{base_path}/images/onsite_test\" # replace with your own test image floder path\n",
        "\n",
        "    # Run Ensemble\n",
        "    if os.path.exists(resnet_pt) and os.path.exists(effnet_pt):\n",
        "        generate_ensemble_submission(resnet_pt, effnet_pt, onsite_csv, onsite_imgs)\n",
        "    else:\n",
        "        print(\"Error: resnet_pt or effnet_pt files does not exist!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8B6X5wDPhpE",
        "outputId": "36e647fd-54ad-4a7d-ee93-5ff36c3a0b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Ensemble from:\n",
            " 1. /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/resnet18_DLsns_task1-3.pt\n",
            " 2. /content/drive/MyDrive/Colab Notebooks/final_project_resources/checkpoints/efficientnet_DLsns_task1-3.pt\n",
            "Dataset ready: 250 valid images\n",
            " Ensemble submission saved to: ensemble_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# ===================================================================\n",
        "# Dataset Class\n",
        "# ===================================================================\n",
        "class RetinaMultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, labels\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# FIXED Model Loading Functions for Task 2 Models\n",
        "# ===================================================================\n",
        "def load_resnet18_task2(ckpt_path, device):\n",
        "    \"\"\"Load ResNet18 model from Task 2 checkpoint (with dropout)\"\"\"\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    num_features = model.fc.in_features\n",
        "    # Task 2 models use Sequential with Dropout\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_features, 3)\n",
        "    )\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_efficientnet_task2(ckpt_path, device):\n",
        "    \"\"\"Load EfficientNet model from Task 2 checkpoint (with dropout)\"\"\"\n",
        "    model = models.efficientnet_b0(pretrained=False)\n",
        "    num_features = model.classifier[1].in_features\n",
        "    # Task 2 models use Sequential with Dropout\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_features, 3)\n",
        "    )\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# TASK 4.1: Weighted Average Ensemble\n",
        "# ===================================================================\n",
        "def weighted_average_ensemble(model_paths, model_types, weights, test_csv, test_image_dir,\n",
        "                               onsite_csv, onsite_image_dir, output_file=\"task4_weighted_ensemble.csv\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"TASK 4.1: Weighted Average Ensemble\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Number of models: {len(model_paths)}\")\n",
        "    print(f\"Weights: {weights}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load all models\n",
        "    models = []\n",
        "    for path, mtype in zip(model_paths, model_types):\n",
        "        print(f\"Loading {mtype} from {os.path.basename(path)}...\")\n",
        "        if mtype == 'resnet18':\n",
        "            model = load_resnet18_task2(path, device)\n",
        "        elif mtype == 'efficientnet':\n",
        "            model = load_efficientnet_task2(path, device)\n",
        "        models.append(model)\n",
        "\n",
        "    # Setup data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Offsite test evaluation\n",
        "    test_ds = RetinaMultiLabelDataset(test_csv, test_image_dir, transform)\n",
        "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(\"\\nEvaluating on offsite test set...\")\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            # Get weighted predictions\n",
        "            weighted_probs = None\n",
        "            for model, weight in zip(models, weights):\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                if weighted_probs is None:\n",
        "                    weighted_probs = probs * weight\n",
        "                else:\n",
        "                    weighted_probs += probs * weight\n",
        "\n",
        "            preds = (weighted_probs > 0.5).int().cpu().numpy()\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate metrics\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "    f1_scores = []\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Offsite Test Results\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        p = precision_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        r = recall_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1_scores.append(f1)\n",
        "        print(f\"{disease}: Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    print(f\"\\nAverage F1-score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "\n",
        "    # Generate onsite predictions\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Generating onsite test predictions...\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    onsite_ds = RetinaMultiLabelDataset(onsite_csv, onsite_image_dir, transform)\n",
        "    onsite_loader = DataLoader(onsite_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    onsite_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in onsite_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            weighted_probs = None\n",
        "            for model, weight in zip(models, weights):\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                if weighted_probs is None:\n",
        "                    weighted_probs = probs * weight\n",
        "                else:\n",
        "                    weighted_probs += probs * weight\n",
        "\n",
        "            preds = (weighted_probs > 0.5).int().cpu().numpy()\n",
        "            onsite_preds.extend(preds)\n",
        "\n",
        "    # Save predictions\n",
        "    onsite_preds = np.array(onsite_preds)\n",
        "    submission_df = pd.read_csv(onsite_csv)\n",
        "    submission_df['D'] = onsite_preds[:, 0]\n",
        "    submission_df['G'] = onsite_preds[:, 1]\n",
        "    submission_df['A'] = onsite_preds[:, 2]\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\" Saved predictions: {output_file}\")\n",
        "    print(f\"\\n{'='*70}\")\n",
        "\n",
        "    return avg_f1\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# TASK 4.2: Max Voting Ensemble\n",
        "# ===================================================================\n",
        "def max_voting_ensemble(model_paths, model_types, test_csv, test_image_dir,\n",
        "                        onsite_csv, onsite_image_dir, output_file=\"task4_max_voting.csv\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"TASK 4.2: Max Voting Ensemble\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Number of models: {len(model_paths)}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load models\n",
        "    models = []\n",
        "    for path, mtype in zip(model_paths, model_types):\n",
        "        print(f\"Loading {mtype} from {os.path.basename(path)}...\")\n",
        "        if mtype == 'resnet18':\n",
        "            model = load_resnet18_task2(path, device)\n",
        "        elif mtype == 'efficientnet':\n",
        "            model = load_efficientnet_task2(path, device)\n",
        "        models.append(model)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Offsite test\n",
        "    test_ds = RetinaMultiLabelDataset(test_csv, test_image_dir, transform)\n",
        "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(\"\\nEvaluating on offsite test set...\")\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            # Collect votes from all models\n",
        "            votes = []\n",
        "            for model in models:\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).int()\n",
        "                votes.append(preds)\n",
        "\n",
        "            # Stack and take majority vote\n",
        "            votes = torch.stack(votes)\n",
        "            majority = (votes.sum(dim=0) > len(models) / 2).int().cpu().numpy()\n",
        "\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(majority)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate metrics\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "    f1_scores = []\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Offsite Test Results\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        p = precision_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        r = recall_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1_scores.append(f1)\n",
        "        print(f\"{disease}: Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    print(f\"\\nAverage F1-score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "\n",
        "    # Onsite predictions\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Generating onsite test predictions...\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    onsite_ds = RetinaMultiLabelDataset(onsite_csv, onsite_image_dir, transform)\n",
        "    onsite_loader = DataLoader(onsite_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    onsite_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in onsite_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            votes = []\n",
        "            for model in models:\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).int()\n",
        "                votes.append(preds)\n",
        "\n",
        "            votes = torch.stack(votes)\n",
        "            majority = (votes.sum(dim=0) > len(models) / 2).int().cpu().numpy()\n",
        "            onsite_preds.extend(majority)\n",
        "\n",
        "    # Save\n",
        "    onsite_preds = np.array(onsite_preds)\n",
        "    submission_df = pd.read_csv(onsite_csv)\n",
        "    submission_df['D'] = onsite_preds[:, 0]\n",
        "    submission_df['G'] = onsite_preds[:, 1]\n",
        "    submission_df['A'] = onsite_preds[:, 2]\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\" Saved predictions: {output_file}\")\n",
        "    print(f\"\\n{'='*70}\")\n",
        "\n",
        "    return avg_f1\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# TASK 4.3: Stacking Ensemble\n",
        "# ===================================================================\n",
        "def stacking_ensemble(model_paths, model_types, train_csv, train_image_dir,\n",
        "                     val_csv, val_image_dir, test_csv, test_image_dir,\n",
        "                     onsite_csv, onsite_image_dir, output_file=\"task4_stacking.csv\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"TASK 4.3: Stacking Ensemble\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Number of base models: {len(model_paths)}\")\n",
        "    print(f\"Meta-learner: Logistic Regression\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load models\n",
        "    models = []\n",
        "    for path, mtype in zip(model_paths, model_types):\n",
        "        print(f\"Loading {mtype} from {os.path.basename(path)}...\")\n",
        "        if mtype == 'resnet18':\n",
        "            model = load_resnet18_task2(path, device)\n",
        "        elif mtype == 'efficientnet':\n",
        "            model = load_efficientnet_task2(path, device)\n",
        "        models.append(model)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Load datasets\n",
        "    train_ds = RetinaMultiLabelDataset(train_csv, train_image_dir, transform)\n",
        "    val_ds = RetinaMultiLabelDataset(val_csv, val_image_dir, transform)\n",
        "    test_ds = RetinaMultiLabelDataset(test_csv, test_image_dir, transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Get base model predictions\n",
        "    def get_predictions(loader):\n",
        "        all_model_preds = [[] for _ in range(len(models))]\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device)\n",
        "                for i, model in enumerate(models):\n",
        "                    outputs = model(imgs)\n",
        "                    probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "                    all_model_preds[i].extend(probs)\n",
        "                all_labels.extend(labels.numpy())\n",
        "\n",
        "        # Concatenate predictions from all models\n",
        "        X = np.concatenate([np.array(preds) for preds in all_model_preds], axis=1)\n",
        "        y = np.array(all_labels)\n",
        "        return X, y\n",
        "\n",
        "    print(\"\\nGenerating base model predictions for training...\")\n",
        "    X_train, y_train = get_predictions(train_loader)\n",
        "\n",
        "    print(\"Generating base model predictions for validation...\")\n",
        "    X_val, y_val = get_predictions(val_loader)\n",
        "\n",
        "    print(\"Generating base model predictions for testing...\")\n",
        "    X_test, y_test = get_predictions(test_loader)\n",
        "\n",
        "    # Train meta-learners (one per disease)\n",
        "    meta_learners = []\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Training Meta-Learners\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        print(f\"Training meta-learner for {disease}...\")\n",
        "        clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        clf.fit(X_train, y_train[:, i])\n",
        "        meta_learners.append(clf)\n",
        "\n",
        "        # Validation\n",
        "        val_preds = clf.predict(X_val)\n",
        "        val_f1 = f1_score(y_val[:, i], val_preds, average='binary', zero_division=0)\n",
        "        print(f\"  Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Test evaluation\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Offsite Test Results\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    test_preds = np.zeros((len(X_test), 3), dtype=int)\n",
        "    f1_scores = []\n",
        "\n",
        "    for i, (disease, clf) in enumerate(zip(disease_names, meta_learners)):\n",
        "        test_preds[:, i] = clf.predict(X_test)\n",
        "\n",
        "        p = precision_score(y_test[:, i], test_preds[:, i], average='binary', zero_division=0)\n",
        "        r = recall_score(y_test[:, i], test_preds[:, i], average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_test[:, i], test_preds[:, i], average='binary', zero_division=0)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        print(f\"{disease}: Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    print(f\"\\nAverage F1-score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "\n",
        "    # Onsite predictions\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Generating onsite test predictions...\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    onsite_ds = RetinaMultiLabelDataset(onsite_csv, onsite_image_dir, transform)\n",
        "    onsite_loader = DataLoader(onsite_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    X_onsite, _ = get_predictions(onsite_loader)\n",
        "\n",
        "    onsite_preds = np.zeros((len(X_onsite), 3), dtype=int)\n",
        "    for i, clf in enumerate(meta_learners):\n",
        "        onsite_preds[:, i] = clf.predict(X_onsite)\n",
        "\n",
        "    # Save\n",
        "    submission_df = pd.read_csv(onsite_csv)\n",
        "    submission_df['D'] = onsite_preds[:, 0]\n",
        "    submission_df['G'] = onsite_preds[:, 1]\n",
        "    submission_df['A'] = onsite_preds[:, 2]\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\" Saved predictions: {output_file}\")\n",
        "    print(f\"\\n{'='*70}\")\n",
        "\n",
        "    return avg_f1\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# MAIN EXECUTION - USING ONLY TASK 2 MODELS\n",
        "# ===================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Base paths\n",
        "    base_path = \"/content/drive/MyDrive/deep learning project/final_project_resources\"\n",
        "    task2_path = \"/content/drive/MyDrive/deep learning project/task2_final\"\n",
        "\n",
        "    # ONLY TASK 2 MODELS (4 models total)\n",
        "    model_paths = [\n",
        "        f\"{task2_path}/resnet18_focal_loss.pt\",\n",
        "        f\"{task2_path}/resnet18_class_balanced.pt\",\n",
        "        f\"{task2_path}/efficientnet_focal_loss.pt\",\n",
        "        f\"{task2_path}/efficientnet_class_balanced.pt\",\n",
        "    ]\n",
        "\n",
        "    model_types = [\n",
        "        'resnet18',\n",
        "        'resnet18',\n",
        "        'efficientnet',\n",
        "        'efficientnet',\n",
        "    ]\n",
        "\n",
        "    # Data paths\n",
        "    train_csv = f\"{base_path}/train.csv\"\n",
        "    train_image_dir = f\"{base_path}/images/train\"\n",
        "    val_csv = f\"{base_path}/val.csv\"\n",
        "    val_image_dir = f\"{base_path}/images/val\"\n",
        "    test_csv = f\"{base_path}/offsite_test.csv\"\n",
        "    test_image_dir = f\"{base_path}/images/offsite_test\"\n",
        "    onsite_csv = f\"{base_path}/onsite_test_submission.csv\"\n",
        "    onsite_image_dir = f\"{base_path}/images/onsite_test\"\n",
        "\n",
        "    # Check if all Task 2 models exist\n",
        "    print(\"=\"*70)\n",
        "    print(\"CHECKING TASK 2 MODEL FILES\")\n",
        "    print(\"=\"*70)\n",
        "    all_exist = True\n",
        "    for path in model_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\" Found: {os.path.basename(path)}\")\n",
        "        else:\n",
        "            print(f\" NOT FOUND: {path}\")\n",
        "            all_exist = False\n",
        "\n",
        "    if not all_exist:\n",
        "        print(\"\\n  Some Task 2 model files are missing!\")\n",
        "        print(\"Please make sure all .pt files are in:\")\n",
        "        print(f\"  {task2_path}/\")\n",
        "        print(\"\\nExpected files:\")\n",
        "        print(\"  - resnet18_focal_loss.pt\")\n",
        "        print(\"  - resnet18_class_balanced.pt\")\n",
        "        print(\"  - efficientnet_focal_loss.pt\")\n",
        "        print(\"  - efficientnet_class_balanced.pt\")\n",
        "        exit()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ALL TASK 2 MODELS FOUND - STARTING ENSEMBLE METHODS\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Run all ensemble methods\n",
        "    results = {}\n",
        "\n",
        "    # Task 4.1: Weighted Average (equal weights)\n",
        "    weights = [0.25, 0.25, 0.25, 0.25]\n",
        "    results['weighted'] = weighted_average_ensemble(\n",
        "        model_paths, model_types, weights,\n",
        "        test_csv, test_image_dir,\n",
        "        onsite_csv, onsite_image_dir,\n",
        "        \"task4_weighted_ensemble.csv\"\n",
        "    )\n",
        "\n",
        "    # Task 4.2: Max Voting\n",
        "    results['voting'] = max_voting_ensemble(\n",
        "        model_paths, model_types,\n",
        "        test_csv, test_image_dir,\n",
        "        onsite_csv, onsite_image_dir,\n",
        "        \"task4_max_voting.csv\"\n",
        "    )\n",
        "\n",
        "    # Task 4.3: Stacking\n",
        "    results['stacking'] = stacking_ensemble(\n",
        "        model_paths, model_types,\n",
        "        train_csv, train_image_dir,\n",
        "        val_csv, val_image_dir,\n",
        "        test_csv, test_image_dir,\n",
        "        onsite_csv, onsite_image_dir,\n",
        "        \"task4_stacking.csv\"\n",
        "    )\n",
        "\n",
        "    # Final Summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TASK 4 COMPLETE - FINAL SUMMARY (Using Task 2 Models Only)\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nOffsite Test Results:\")\n",
        "    for method, f1 in results.items():\n",
        "        print(f\"  {method.capitalize():20s}: F1 = {f1:.4f} ({f1*100:.2f}%)\")\n",
        "\n",
        "    best_method = max(results, key=results.get)\n",
        "    best_f1 = results[best_method]\n",
        "\n",
        "    print(f\"\\n Best Method: {best_method.upper()} with F1 = {best_f1:.4f}\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated submission files:\")\n",
        "    print(\"  - task4_weighted_ensemble.csv\")\n",
        "    print(\"  - task4_max_voting.csv\")\n",
        "    print(\"  - task4_stacking.csv\")\n",
        "    print(f\"\\n Submit task4_{best_method}.csv to Kaggle for best results!\")\n",
        "    print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hF8vVgzdPT8",
        "outputId": "22b653f2-af8c-4bcb-f11e-88622a3de003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Device: cuda\n",
            "======================================================================\n",
            "CHECKING TASK 2 MODEL FILES\n",
            "======================================================================\n",
            " Found: resnet18_focal_loss.pt\n",
            " Found: resnet18_class_balanced.pt\n",
            " Found: efficientnet_focal_loss.pt\n",
            " Found: efficientnet_class_balanced.pt\n",
            "\n",
            "======================================================================\n",
            "ALL TASK 2 MODELS FOUND - STARTING ENSEMBLE METHODS\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TASK 4.1: Weighted Average Ensemble\n",
            "======================================================================\n",
            "Number of models: 4\n",
            "Weights: [0.25, 0.25, 0.25, 0.25]\n",
            "======================================================================\n",
            "\n",
            "Loading resnet18 from resnet18_focal_loss.pt...\n",
            "Loading resnet18 from resnet18_class_balanced.pt...\n",
            "Loading efficientnet from efficientnet_focal_loss.pt...\n",
            "Loading efficientnet from efficientnet_class_balanced.pt...\n",
            "\n",
            "Evaluating on offsite test set...\n",
            "\n",
            "======================================================================\n",
            "Offsite Test Results\n",
            "======================================================================\n",
            "\n",
            "DR: Precision=0.8859, Recall=0.9429, F1=0.9135\n",
            "Glaucoma: Precision=0.7872, Recall=0.7551, F1=0.7708\n",
            "AMD: Precision=0.7368, Recall=0.6364, F1=0.6829\n",
            "\n",
            "Average F1-score: 0.7891 (78.91%)\n",
            "\n",
            "======================================================================\n",
            "Generating onsite test predictions...\n",
            "======================================================================\n",
            "\n",
            " Saved predictions: task4_weighted_ensemble.csv\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TASK 4.2: Max Voting Ensemble\n",
            "======================================================================\n",
            "Number of models: 4\n",
            "======================================================================\n",
            "\n",
            "Loading resnet18 from resnet18_focal_loss.pt...\n",
            "Loading resnet18 from resnet18_class_balanced.pt...\n",
            "Loading efficientnet from efficientnet_focal_loss.pt...\n",
            "Loading efficientnet from efficientnet_class_balanced.pt...\n",
            "\n",
            "Evaluating on offsite test set...\n",
            "\n",
            "======================================================================\n",
            "Offsite Test Results\n",
            "======================================================================\n",
            "\n",
            "DR: Precision=0.9220, Recall=0.9286, F1=0.9253\n",
            "Glaucoma: Precision=0.8140, Recall=0.7143, F1=0.7609\n",
            "AMD: Precision=0.7778, Recall=0.6364, F1=0.7000\n",
            "\n",
            "Average F1-score: 0.7954 (79.54%)\n",
            "\n",
            "======================================================================\n",
            "Generating onsite test predictions...\n",
            "======================================================================\n",
            "\n",
            " Saved predictions: task4_max_voting.csv\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TASK 4.3: Stacking Ensemble\n",
            "======================================================================\n",
            "Number of base models: 4\n",
            "Meta-learner: Logistic Regression\n",
            "======================================================================\n",
            "\n",
            "Loading resnet18 from resnet18_focal_loss.pt...\n",
            "Loading resnet18 from resnet18_class_balanced.pt...\n",
            "Loading efficientnet from efficientnet_focal_loss.pt...\n",
            "Loading efficientnet from efficientnet_class_balanced.pt...\n",
            "\n",
            "Generating base model predictions for training...\n",
            "Generating base model predictions for validation...\n",
            "Generating base model predictions for testing...\n",
            "\n",
            "======================================================================\n",
            "Training Meta-Learners\n",
            "======================================================================\n",
            "\n",
            "Training meta-learner for DR...\n",
            "  Validation F1: 0.8472\n",
            "Training meta-learner for Glaucoma...\n",
            "  Validation F1: 0.8155\n",
            "Training meta-learner for AMD...\n",
            "  Validation F1: 0.7342\n",
            "\n",
            "======================================================================\n",
            "Offsite Test Results\n",
            "======================================================================\n",
            "\n",
            "DR: Precision=0.8973, Recall=0.9357, F1=0.9161\n",
            "Glaucoma: Precision=0.8649, Recall=0.6531, F1=0.7442\n",
            "AMD: Precision=0.7000, Recall=0.6364, F1=0.6667\n",
            "\n",
            "Average F1-score: 0.7756 (77.56%)\n",
            "\n",
            "======================================================================\n",
            "Generating onsite test predictions...\n",
            "======================================================================\n",
            "\n",
            " Saved predictions: task4_stacking.csv\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TASK 4 COMPLETE - FINAL SUMMARY (Using Task 2 Models Only)\n",
            "======================================================================\n",
            "\n",
            "Offsite Test Results:\n",
            "  Weighted            : F1 = 0.7891 (78.91%)\n",
            "  Voting              : F1 = 0.7954 (79.54%)\n",
            "  Stacking            : F1 = 0.7756 (77.56%)\n",
            "\n",
            " Best Method: VOTING with F1 = 0.7954\n",
            "======================================================================\n",
            "\n",
            "Generated submission files:\n",
            "  - task4_weighted_ensemble.csv\n",
            "  - task4_max_voting.csv\n",
            "  - task4_stacking.csv\n",
            "\n",
            " Submit task4_voting.csv to Kaggle for best results!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Task 4 using task 1 , 2 and 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# ===================================================================\n",
        "# Dataset Class\n",
        "# ===================================================================\n",
        "class RetinaMultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, labels\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# Model Loading Functions\n",
        "# ===================================================================\n",
        "def load_resnet18_task1(ckpt_path, device):\n",
        "    \"\"\"Load ResNet18 from Task 1 (simple fc layer)\"\"\"\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 3)\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_efficientnet_task1(ckpt_path, device):\n",
        "    \"\"\"Load EfficientNet from Task 1 (simple classifier)\"\"\"\n",
        "    model = models.efficientnet_b0(pretrained=False)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 3)\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_resnet18_task2(ckpt_path, device):\n",
        "    \"\"\"Load ResNet18 from Task 2 (with dropout)\"\"\"\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_features, 3)\n",
        "    )\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_efficientnet_task2(ckpt_path, device):\n",
        "    \"\"\"Load EfficientNet from Task 2 (with dropout)\"\"\"\n",
        "    model = models.efficientnet_b0(pretrained=False)\n",
        "    num_features = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_features, 3)\n",
        "    )\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_resnet18_task3_se(ckpt_path, device):\n",
        "    \"\"\"Load ResNet18 from Task 3 with SE attention\"\"\"\n",
        "    # SE Block\n",
        "    class SEBlock(nn.Module):\n",
        "        def __init__(self, channels, reduction=16):\n",
        "            super(SEBlock, self).__init__()\n",
        "            reduced_channels = max(channels // reduction, 1)\n",
        "            self.fc1 = nn.Linear(channels, reduced_channels, bias=False)\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "            self.fc2 = nn.Linear(reduced_channels, channels, bias=False)\n",
        "            self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch, channels, _, _ = x.size()\n",
        "            squeeze = torch.nn.functional.adaptive_avg_pool2d(x, 1).view(batch, channels)\n",
        "            excitation = self.fc1(squeeze)\n",
        "            excitation = self.relu(excitation)\n",
        "            excitation = self.fc2(excitation)\n",
        "            excitation = self.sigmoid(excitation)\n",
        "            excitation = excitation.view(batch, channels, 1, 1)\n",
        "            return x * excitation.expand_as(x)\n",
        "\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    original_layer4 = model.layer4\n",
        "    model.layer4 = nn.Sequential(\n",
        "        original_layer4,\n",
        "        SEBlock(512, reduction=16)\n",
        "    )\n",
        "    model.fc = nn.Linear(model.fc.in_features, 3)\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=False)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_resnet18_task3_mha(ckpt_path, device):\n",
        "    \"\"\"Load ResNet18 from Task 3 with MHA attention\"\"\"\n",
        "    # MHA Block\n",
        "    class MultiHeadAttention(nn.Module):\n",
        "        def __init__(self, channels, num_heads=8, reduction=4):\n",
        "            super(MultiHeadAttention, self).__init__()\n",
        "            self.num_heads = num_heads\n",
        "            self.head_dim = channels // num_heads\n",
        "            self.scale = self.head_dim ** -0.5\n",
        "            self.reduction = reduction\n",
        "\n",
        "            if reduction > 1:\n",
        "                self.pool = nn.AvgPool2d(kernel_size=reduction, stride=reduction)\n",
        "            else:\n",
        "                self.pool = nn.Identity()\n",
        "\n",
        "            self.qkv = nn.Linear(channels, channels * 3, bias=False)\n",
        "            self.proj_out = nn.Linear(channels, channels, bias=False)\n",
        "            self.norm = nn.LayerNorm(channels)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch, channels, H, W = x.size()\n",
        "            identity = x\n",
        "            x_reduced = self.pool(x)\n",
        "            _, _, h, w = x_reduced.size()\n",
        "            seq_len = h * w\n",
        "            x_flat = x_reduced.flatten(2).transpose(1, 2)\n",
        "            qkv = self.qkv(x_flat)\n",
        "            qkv = qkv.reshape(batch, seq_len, 3, self.num_heads, self.head_dim)\n",
        "            qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "            q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "            attn_scores = (q @ k.transpose(-2, -1)) * self.scale\n",
        "            attn_weights = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
        "            attn_out = attn_weights @ v\n",
        "            attn_out = attn_out.transpose(1, 2).contiguous()\n",
        "            attn_out = attn_out.reshape(batch, seq_len, channels)\n",
        "            out = self.proj_out(attn_out)\n",
        "            out = self.norm(out)\n",
        "            out = out.transpose(1, 2).reshape(batch, channels, h, w)\n",
        "            if self.reduction > 1:\n",
        "                out = torch.nn.functional.interpolate(out, size=(H, W), mode='bilinear', align_corners=False)\n",
        "            return identity + out\n",
        "\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    original_layer4 = model.layer4\n",
        "    model.layer4 = nn.Sequential(\n",
        "        original_layer4,\n",
        "        MultiHeadAttention(512, num_heads=8, reduction=2)\n",
        "    )\n",
        "    model.fc = nn.Linear(model.fc.in_features, 3)\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=False)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_model_auto(ckpt_path, model_type, task, device):\n",
        "    \"\"\"Automatically load model based on type and task\"\"\"\n",
        "    if task == 1:\n",
        "        if model_type == 'resnet18':\n",
        "            return load_resnet18_task1(ckpt_path, device)\n",
        "        elif model_type == 'efficientnet':\n",
        "            return load_efficientnet_task1(ckpt_path, device)\n",
        "    elif task == 2:\n",
        "        if model_type == 'resnet18':\n",
        "            return load_resnet18_task2(ckpt_path, device)\n",
        "        elif model_type == 'efficientnet':\n",
        "            return load_efficientnet_task2(ckpt_path, device)\n",
        "    elif task == 3:\n",
        "        if 'se' in ckpt_path.lower():\n",
        "            return load_resnet18_task3_se(ckpt_path, device)\n",
        "        elif 'mha' in ckpt_path.lower():\n",
        "            return load_resnet18_task3_mha(ckpt_path, device)\n",
        "\n",
        "    raise ValueError(f\"Unknown model configuration: {model_type}, task {task}\")\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# METHOD 1: Super Ensemble with TTA + Optimized Weights\n",
        "# ===================================================================\n",
        "def ultimate_weighted_ensemble(model_configs, test_csv, test_image_dir,\n",
        "                               onsite_csv, onsite_image_dir,\n",
        "                               output_file=\"task4_ultimate_weighted.csv\",\n",
        "                               use_tta=True):\n",
        "    \"\"\"\n",
        "    Ultimate weighted ensemble using ALL models with optimized weights\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\" ULTIMATE METHOD 1: Super Weighted Ensemble\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total models: {len(model_configs)}\")\n",
        "    print(f\"Test-Time Augmentation: {use_tta}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load all models\n",
        "    models = []\n",
        "    weights = []\n",
        "\n",
        "    for config in model_configs:\n",
        "        print(f\"Loading {config['name']}...\")\n",
        "        model = load_model_auto(config['path'], config['type'], config['task'], device)\n",
        "        models.append(model)\n",
        "        weights.append(config['weight'])\n",
        "\n",
        "    # Normalize weights\n",
        "    weights = np.array(weights)\n",
        "    weights = weights / weights.sum()\n",
        "\n",
        "    print(f\"\\n Model Weights:\")\n",
        "    for config, w in zip(model_configs, weights):\n",
        "        print(f\"  {config['name']:40s}: {w:.4f}\")\n",
        "\n",
        "    # Setup data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Offsite test evaluation\n",
        "    test_ds = RetinaMultiLabelDataset(test_csv, test_image_dir, transform)\n",
        "    test_loader = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(\"\\n Evaluating on offsite test set...\")\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                # TTA: Original + H-flip + V-flip\n",
        "                all_augmented_probs = []\n",
        "\n",
        "                for aug_imgs in [imgs, torch.flip(imgs, dims=[3]), torch.flip(imgs, dims=[2])]:\n",
        "                    weighted_probs = None\n",
        "                    for model, weight in zip(models, weights):\n",
        "                        outputs = model(aug_imgs)\n",
        "                        probs = torch.sigmoid(outputs)\n",
        "                        if weighted_probs is None:\n",
        "                            weighted_probs = probs * weight\n",
        "                        else:\n",
        "                            weighted_probs += probs * weight\n",
        "                    all_augmented_probs.append(weighted_probs)\n",
        "\n",
        "                # Average TTA predictions\n",
        "                final_probs = torch.stack(all_augmented_probs).mean(dim=0)\n",
        "            else:\n",
        "                weighted_probs = None\n",
        "                for model, weight in zip(models, weights):\n",
        "                    outputs = model(imgs)\n",
        "                    probs = torch.sigmoid(outputs)\n",
        "                    if weighted_probs is None:\n",
        "                        weighted_probs = probs * weight\n",
        "                    else:\n",
        "                        weighted_probs += probs * weight\n",
        "                final_probs = weighted_probs\n",
        "\n",
        "            preds = (final_probs > 0.5).int().cpu().numpy()\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate metrics\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "    f1_scores = []\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\" Offsite Test Results\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        p = precision_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        r = recall_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1_scores.append(f1)\n",
        "        print(f\"{disease:10s}: Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" Average F1-score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Generate onsite predictions\n",
        "    print(\" Generating onsite test predictions...\")\n",
        "\n",
        "    onsite_ds = RetinaMultiLabelDataset(onsite_csv, onsite_image_dir, transform)\n",
        "    onsite_loader = DataLoader(onsite_ds, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "    onsite_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in onsite_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                all_augmented_probs = []\n",
        "                for aug_imgs in [imgs, torch.flip(imgs, dims=[3]), torch.flip(imgs, dims=[2])]:\n",
        "                    weighted_probs = None\n",
        "                    for model, weight in zip(models, weights):\n",
        "                        outputs = model(aug_imgs)\n",
        "                        probs = torch.sigmoid(outputs)\n",
        "                        if weighted_probs is None:\n",
        "                            weighted_probs = probs * weight\n",
        "                        else:\n",
        "                            weighted_probs += probs * weight\n",
        "                    all_augmented_probs.append(weighted_probs)\n",
        "                final_probs = torch.stack(all_augmented_probs).mean(dim=0)\n",
        "            else:\n",
        "                weighted_probs = None\n",
        "                for model, weight in zip(models, weights):\n",
        "                    outputs = model(imgs)\n",
        "                    probs = torch.sigmoid(outputs)\n",
        "                    if weighted_probs is None:\n",
        "                        weighted_probs = probs * weight\n",
        "                    else:\n",
        "                        weighted_probs += probs * weight\n",
        "                final_probs = weighted_probs\n",
        "\n",
        "            preds = (final_probs > 0.5).int().cpu().numpy()\n",
        "            onsite_preds.extend(preds)\n",
        "\n",
        "    # Save predictions\n",
        "    onsite_preds = np.array(onsite_preds)\n",
        "    submission_df = pd.read_csv(onsite_csv)\n",
        "    submission_df['D'] = onsite_preds[:, 0]\n",
        "    submission_df['G'] = onsite_preds[:, 1]\n",
        "    submission_df['A'] = onsite_preds[:, 2]\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\" Saved predictions: {output_file}\\n\")\n",
        "\n",
        "    return avg_f1\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# METHOD 2: Deep Stacking with All Models\n",
        "# ===================================================================\n",
        "def ultimate_stacking_ensemble(model_configs, train_csv, train_image_dir,\n",
        "                               val_csv, val_image_dir, test_csv, test_image_dir,\n",
        "                               onsite_csv, onsite_image_dir,\n",
        "                               output_file=\"task4_ultimate_stacking.csv\"):\n",
        "    \"\"\"\n",
        "    Deep stacking with Random Forest using ALL models\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\" ULTIMATE METHOD 2: Deep Stacking Ensemble\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Base models: {len(model_configs)}\")\n",
        "    print(f\"Meta-learner: Random Forest\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load models\n",
        "    models = []\n",
        "    for config in model_configs:\n",
        "        print(f\"Loading {config['name']}...\")\n",
        "        model = load_model_auto(config['path'], config['type'], config['task'], device)\n",
        "        models.append(model)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Load datasets\n",
        "    train_ds = RetinaMultiLabelDataset(train_csv, train_image_dir, transform)\n",
        "    val_ds = RetinaMultiLabelDataset(val_csv, val_image_dir, transform)\n",
        "    test_ds = RetinaMultiLabelDataset(test_csv, test_image_dir, transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Get base model predictions\n",
        "    def get_predictions(loader, desc=\"\"):\n",
        "        print(f\"  Generating predictions {desc}...\")\n",
        "        all_model_preds = [[] for _ in range(len(models))]\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device)\n",
        "                for i, model in enumerate(models):\n",
        "                    outputs = model(imgs)\n",
        "                    probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "                    all_model_preds[i].extend(probs)\n",
        "                all_labels.extend(labels.numpy())\n",
        "\n",
        "        X = np.concatenate([np.array(preds) for preds in all_model_preds], axis=1)\n",
        "        y = np.array(all_labels)\n",
        "        return X, y\n",
        "\n",
        "    print(\"\\n Generating meta-features...\")\n",
        "    X_train, y_train = get_predictions(train_loader, \"for train\")\n",
        "    X_val, y_val = get_predictions(val_loader, \"for validation\")\n",
        "    X_test, y_test = get_predictions(test_loader, \"for test\")\n",
        "\n",
        "    print(f\"\\n  Meta-feature shape: {X_train.shape}\")\n",
        "\n",
        "    # Train meta-learners\n",
        "    meta_learners = []\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "\n",
        "    print(f\"\\n Training Meta-Learners...\")\n",
        "\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        print(f\"\\n  {disease}:\")\n",
        "\n",
        "\n",
        "        clf = RandomForestClassifier(\n",
        "            n_estimators=300,\n",
        "            max_depth=15,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            max_features='sqrt',\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        clf.fit(X_train, y_train[:, i])\n",
        "        meta_learners.append(clf)\n",
        "\n",
        "        # Validation\n",
        "        val_preds = clf.predict(X_val)\n",
        "        val_f1 = f1_score(y_val[:, i], val_preds, average='binary', zero_division=0)\n",
        "        print(f\"    Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Test evaluation\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\" Offsite Test Results\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    test_preds = np.zeros((len(X_test), 3), dtype=int)\n",
        "    f1_scores = []\n",
        "\n",
        "    for i, (disease, clf) in enumerate(zip(disease_names, meta_learners)):\n",
        "        test_preds[:, i] = clf.predict(X_test)\n",
        "\n",
        "        p = precision_score(y_test[:, i], test_preds[:, i], average='binary', zero_division=0)\n",
        "        r = recall_score(y_test[:, i], test_preds[:, i], average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_test[:, i], test_preds[:, i], average='binary', zero_division=0)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        print(f\"{disease:10s}: Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" Average F1-score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Onsite predictions\n",
        "    print(\" Generating onsite test predictions...\")\n",
        "\n",
        "    onsite_ds = RetinaMultiLabelDataset(onsite_csv, onsite_image_dir, transform)\n",
        "    onsite_loader = DataLoader(onsite_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    X_onsite, _ = get_predictions(onsite_loader, \"for onsite\")\n",
        "\n",
        "    onsite_preds = np.zeros((len(X_onsite), 3), dtype=int)\n",
        "    for i, clf in enumerate(meta_learners):\n",
        "        onsite_preds[:, i] = clf.predict(X_onsite)\n",
        "\n",
        "    # Save\n",
        "    submission_df = pd.read_csv(onsite_csv)\n",
        "    submission_df['D'] = onsite_preds[:, 0]\n",
        "    submission_df['G'] = onsite_preds[:, 1]\n",
        "    submission_df['A'] = onsite_preds[:, 2]\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\" Saved predictions: {output_file}\\n\")\n",
        "\n",
        "    return avg_f1\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "#  METHOD 3: Adaptive Threshold with All Models\n",
        "# ===================================================================\n",
        "def ultimate_adaptive_threshold(model_configs, val_csv, val_image_dir,\n",
        "                                test_csv, test_image_dir,\n",
        "                                onsite_csv, onsite_image_dir,\n",
        "                                output_file=\"task4_ultimate_adaptive.csv\"):\n",
        "    \"\"\"\n",
        "    Adaptive threshold optimization using ALL models\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\" ULTIMATE METHOD 3: Adaptive Threshold Optimization\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total models: {len(model_configs)}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load models\n",
        "    models = []\n",
        "    weights = []\n",
        "\n",
        "    for config in model_configs:\n",
        "        print(f\"Loading {config['name']}...\")\n",
        "        model = load_model_auto(config['path'], config['type'], config['task'], device)\n",
        "        models.append(model)\n",
        "        weights.append(config['weight'])\n",
        "\n",
        "    # Normalize weights\n",
        "    weights = np.array(weights)\n",
        "    weights = weights / weights.sum()\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Find optimal thresholds on validation set\n",
        "    print(\"\\n Finding optimal thresholds on validation set...\")\n",
        "    val_ds = RetinaMultiLabelDataset(val_csv, val_image_dir, transform)\n",
        "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    val_probs_all = []\n",
        "    val_labels_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            weighted_probs = None\n",
        "            for model, weight in zip(models, weights):\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                if weighted_probs is None:\n",
        "                    weighted_probs = probs * weight\n",
        "                else:\n",
        "                    weighted_probs += probs * weight\n",
        "\n",
        "            val_probs_all.extend(weighted_probs.cpu().numpy())\n",
        "            val_labels_all.extend(labels.numpy())\n",
        "\n",
        "    val_probs_all = np.array(val_probs_all)\n",
        "    val_labels_all = np.array(val_labels_all)\n",
        "\n",
        "    # Find optimal threshold for each disease\n",
        "    optimal_thresholds = []\n",
        "    disease_names = [\"DR\", \"Glaucoma\", \"AMD\"]\n",
        "\n",
        "    print(\"\\n Optimal thresholds per disease:\")\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        best_threshold = 0.5\n",
        "        best_f1 = 0\n",
        "\n",
        "        # Try different thresholds\n",
        "        for threshold in np.arange(0.25, 0.75, 0.025):\n",
        "            preds = (val_probs_all[:, i] > threshold).astype(int)\n",
        "            f1 = f1_score(val_labels_all[:, i], preds, average='binary', zero_division=0)\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_threshold = threshold\n",
        "\n",
        "        optimal_thresholds.append(best_threshold)\n",
        "        print(f\"  {disease:10s}: {best_threshold:.3f} (Val F1={best_f1:.4f})\")\n",
        "\n",
        "    # Test with optimal thresholds\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\" Evaluating on offsite test set...\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    test_ds = RetinaMultiLabelDataset(test_csv, test_image_dir, transform)\n",
        "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            weighted_probs = None\n",
        "            for model, weight in zip(models, weights):\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                if weighted_probs is None:\n",
        "                    weighted_probs = probs * weight\n",
        "                else:\n",
        "                    weighted_probs += probs * weight\n",
        "\n",
        "\n",
        "            probs_np = weighted_probs.cpu().numpy()\n",
        "            preds = np.zeros_like(probs_np, dtype=int)\n",
        "            for i, threshold in enumerate(optimal_thresholds):\n",
        "                preds[:, i] = (probs_np[:, i] > threshold).astype(int)\n",
        "\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate metrics\n",
        "    f1_scores = []\n",
        "\n",
        "    print(\"Offsite Test Results:\\n\")\n",
        "\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        p = precision_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        r = recall_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1 = f1_score(y_true[:, i], y_pred[:, i], average='binary', zero_division=0)\n",
        "        f1_scores.append(f1)\n",
        "        print(f\"{disease:10s}: Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f} (threshold={optimal_thresholds[i]:.3f})\")\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" Average F1-score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Onsite predictions\n",
        "    print(\" Generating onsite test predictions...\")\n",
        "\n",
        "    onsite_ds = RetinaMultiLabelDataset(onsite_csv, onsite_image_dir, transform)\n",
        "    onsite_loader = DataLoader(onsite_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    onsite_preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in onsite_loader:\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            weighted_probs = None\n",
        "            for model, weight in zip(models, weights):\n",
        "                outputs = model(imgs)\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                if weighted_probs is None:\n",
        "                    weighted_probs = probs * weight\n",
        "                else:\n",
        "                    weighted_probs += probs * weight\n",
        "\n",
        "            probs_np = weighted_probs.cpu().numpy()\n",
        "            preds = np.zeros_like(probs_np, dtype=int)\n",
        "            for i, threshold in enumerate(optimal_thresholds):\n",
        "                preds[:, i] = (probs_np[:, i] > threshold).astype(int)\n",
        "\n",
        "            onsite_preds.extend(preds)\n",
        "\n",
        "    # Save\n",
        "    onsite_preds = np.array(onsite_preds)\n",
        "    submission_df = pd.read_csv(onsite_csv)\n",
        "    submission_df['D'] = onsite_preds[:, 0]\n",
        "    submission_df['G'] = onsite_preds[:, 1]\n",
        "    submission_df['A'] = onsite_preds[:, 2]\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "    print(f\" Saved predictions: {output_file}\\n\")\n",
        "\n",
        "    return avg_f1\n",
        "# ===================================================================\n",
        "# MAIN EXECUTION - USING ALL TASK 1,2,3 MODELS\n",
        "# ===================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Base paths\n",
        "    base_path = \"/content/drive/MyDrive/deep learning project/final_project_resources\"\n",
        "    task1_path = \"/content/drive/MyDrive/deep learning project/task1_final\"\n",
        "    task2_path = \"/content/drive/MyDrive/deep learning project/task2_final\"\n",
        "    task3_path = \"/content/drive/MyDrive/deep learning project/task3_final\"\n",
        "\n",
        "    # Data paths\n",
        "    train_csv = f\"{base_path}/train.csv\"\n",
        "    train_image_dir = f\"{base_path}/images/train\"\n",
        "    val_csv = f\"{base_path}/val.csv\"\n",
        "    val_image_dir = f\"{base_path}/images/val\"\n",
        "    test_csv = f\"{base_path}/offsite_test.csv\"\n",
        "    test_image_dir = f\"{base_path}/images/offsite_test\"\n",
        "    onsite_csv = f\"{base_path}/onsite_test_submission.csv\"\n",
        "    onsite_image_dir = f\"{base_path}/images/onsite_test\"\n",
        "\n",
        "    # -------------------------------------------------------------------\n",
        "    # Build model configs automatically from folders\n",
        "    # -------------------------------------------------------------------\n",
        "    def build_model_configs(task1_path, task2_path, task3_path):\n",
        "        model_configs = []\n",
        "\n",
        "        # Task 1 models\n",
        "        if os.path.exists(task1_path):\n",
        "            for f in sorted(os.listdir(task1_path)):\n",
        "                if f.endswith(\".pt\"):\n",
        "                    f_lower = f.lower()\n",
        "                    if \"resnet\" in f_lower:\n",
        "                        mtype = \"resnet18\"\n",
        "                    elif \"efficientnet\" in f_lower:\n",
        "                        mtype = \"efficientnet\"\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                    model_configs.append({\n",
        "                        \"name\": f\"T1_{f}\",\n",
        "                        \"path\": os.path.join(task1_path, f),\n",
        "                        \"type\": mtype,\n",
        "                        \"task\": 1,\n",
        "                        \"weight\": 1.00\n",
        "                    })\n",
        "\n",
        "        # Task 2 models\n",
        "        if os.path.exists(task2_path):\n",
        "            for f in sorted(os.listdir(task2_path)):\n",
        "                if f.endswith(\".pt\"):\n",
        "                    f_lower = f.lower()\n",
        "                    if \"resnet\" in f_lower:\n",
        "                        mtype = \"resnet18\"\n",
        "                    elif \"efficientnet\" in f_lower:\n",
        "                        mtype = \"efficientnet\"\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                    model_configs.append({\n",
        "                        \"name\": f\"T2_{f}\",\n",
        "                        \"path\": os.path.join(task2_path, f),\n",
        "                        \"type\": mtype,\n",
        "                        \"task\": 2,\n",
        "                        \"weight\": 1.00\n",
        "                    })\n",
        "\n",
        "        # Task 3 models (ResNet18 SE/MHA)\n",
        "        if os.path.exists(task3_path):\n",
        "            for f in sorted(os.listdir(task3_path)):\n",
        "                if f.endswith(\".pt\"):\n",
        "                    f_lower = f.lower()\n",
        "                    if \"resnet\" in f_lower:\n",
        "                        model_configs.append({\n",
        "                            \"name\": f\"T3_{f}\",\n",
        "                            \"path\": os.path.join(task3_path, f),\n",
        "                            \"type\": \"resnet18\",\n",
        "                            \"task\": 3,\n",
        "                            \"weight\": 1.00\n",
        "                        })\n",
        "\n",
        "        return model_configs\n",
        "\n",
        "    model_configs = build_model_configs(task1_path, task2_path, task3_path)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"CHECKING ALL MODEL FILES (TASK 1 + TASK 2 + TASK 3)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if len(model_configs) == 0:\n",
        "        print(\" No .pt files found in task1_final/task2_final/task3_final!\")\n",
        "        raise SystemExit\n",
        "\n",
        "    all_exist = True\n",
        "    for cfg in model_configs:\n",
        "        if os.path.exists(cfg[\"path\"]):\n",
        "            print(f\" Found: {cfg['name']}\")\n",
        "        else:\n",
        "            print(f\" NOT FOUND: {cfg['path']}\")\n",
        "            all_exist = False\n",
        "\n",
        "    if not all_exist:\n",
        "        print(\"\\n Some model files are missing. Please fix paths and rerun.\")\n",
        "        raise SystemExit\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ALL MODELS FOUND - STARTING ULTIMATE TASK 4 METHODS\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # -------------------------------------------------------------------\n",
        "    # Run all ultimate methods\n",
        "    # -------------------------------------------------------------------\n",
        "    results = {}\n",
        "\n",
        "    # Ultimate Method 1: Weighted Ensemble (with TTA)\n",
        "    results[\"ultimate_weighted_tta\"] = ultimate_weighted_ensemble(\n",
        "        model_configs,\n",
        "        test_csv, test_image_dir,\n",
        "        onsite_csv, onsite_image_dir,\n",
        "        output_file=\"task4_ultimate_weighted_tta.csv\",\n",
        "        use_tta=True\n",
        "    )\n",
        "\n",
        "    # Ultimate Method 1 (No TTA)\n",
        "    results[\"ultimate_weighted_no_tta\"] = ultimate_weighted_ensemble(\n",
        "        model_configs,\n",
        "        test_csv, test_image_dir,\n",
        "        onsite_csv, onsite_image_dir,\n",
        "        output_file=\"task4_ultimate_weighted_no_tta.csv\",\n",
        "        use_tta=False\n",
        "    )\n",
        "\n",
        "    # Ultimate Method 2: Deep Stacking\n",
        "    results[\"ultimate_stacking\"] = ultimate_stacking_ensemble(\n",
        "        model_configs,\n",
        "        train_csv, train_image_dir,\n",
        "        val_csv, val_image_dir,\n",
        "        test_csv, test_image_dir,\n",
        "        onsite_csv, onsite_image_dir,\n",
        "        output_file=\"task4_ultimate_stacking.csv\"\n",
        "    )\n",
        "\n",
        "    # Ultimate Method 3: Adaptive Threshold (Val-optimized thresholds)\n",
        "    results[\"ultimate_adaptive_threshold\"] = ultimate_adaptive_threshold(\n",
        "        model_configs,\n",
        "        val_csv, val_image_dir,\n",
        "        test_csv, test_image_dir,\n",
        "        onsite_csv, onsite_image_dir,\n",
        "        output_file=\"task4_ultimate_adaptive.csv\"\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------------------------\n",
        "    # Final Summary\n",
        "    # -------------------------------------------------------------------\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" TASK 4 COMPLETE - ULTIMATE FINAL SUMMARY (All Tasks 1+2+3 Models)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nOffsite Test Results:\")\n",
        "    for method, f1 in results.items():\n",
        "        print(f\"  {method:30s}: F1 = {f1:.4f} ({f1*100:.2f}%)\")\n",
        "\n",
        "    best_method = max(results, key=results.get)\n",
        "    best_f1 = results[best_method]\n",
        "\n",
        "    print(f\"\\n Best Method: {best_method.upper()} with F1 = {best_f1:.4f} ({best_f1*100:.2f}%)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nGenerated submission files:\")\n",
        "    print(\"  - task4_ultimate_weighted_tta.csv\")\n",
        "    print(\"  - task4_ultimate_weighted_no_tta.csv\")\n",
        "    print(\"  - task4_ultimate_stacking.csv\")\n",
        "    print(\"  - task4_ultimate_adaptive.csv\")\n",
        "\n",
        "    # Suggest best file name\n",
        "    best_file_map = {\n",
        "        \"ultimate_weighted_tta\": \"task4_ultimate_weighted_tta.csv\",\n",
        "        \"ultimate_weighted_no_tta\": \"task4_ultimate_weighted_no_tta.csv\",\n",
        "        \"ultimate_stacking\": \"task4_ultimate_stacking.csv\",\n",
        "        \"ultimate_adaptive_threshold\": \"task4_ultimate_adaptive.csv\",\n",
        "    }\n",
        "\n",
        "    print(f\"\\n Submit this file to Kaggle for best results:\")\n",
        "    print(f\"  - {best_file_map.get(best_method, 'UNKNOWN')}\")\n",
        "    print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTm8V2RhpFp0",
        "outputId": "e9e7721e-8889-4d87-fd8e-ace20e5ebf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Device: cuda\n",
            "======================================================================\n",
            "CHECKING ALL MODEL FILES (TASK 1 + TASK 2 + TASK 3)\n",
            "======================================================================\n",
            " Found: T1_efficientnet_DLsns_task1-1.pt\n",
            " Found: T1_efficientnet_DLsns_task1-2.pt\n",
            " Found: T1_efficientnet_DLsns_task1-3.pt\n",
            " Found: T1_resnet18_DLsns_task1-1.pt\n",
            " Found: T1_resnet18_DLsns_task1-2.pt\n",
            " Found: T1_resnet18_DLsns_task1-3.pt\n",
            " Found: T2_efficientnet_class_balanced.pt\n",
            " Found: T2_efficientnet_focal_loss.pt\n",
            " Found: T2_resnet18_class_balanced.pt\n",
            " Found: T2_resnet18_focal_loss.pt\n",
            " Found: T3_best_resnet18_task3_mha.pt\n",
            " Found: T3_best_resnet18_task3_se.pt\n",
            "\n",
            "======================================================================\n",
            "ALL MODELS FOUND - STARTING ULTIMATE TASK 4 METHODS\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            " ULTIMATE METHOD 1: Super Weighted Ensemble\n",
            "======================================================================\n",
            "Total models: 12\n",
            "Test-Time Augmentation: True\n",
            "======================================================================\n",
            "\n",
            "Loading T1_efficientnet_DLsns_task1-1.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-2.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-3.pt...\n",
            "Loading T1_resnet18_DLsns_task1-1.pt...\n",
            "Loading T1_resnet18_DLsns_task1-2.pt...\n",
            "Loading T1_resnet18_DLsns_task1-3.pt...\n",
            "Loading T2_efficientnet_class_balanced.pt...\n",
            "Loading T2_efficientnet_focal_loss.pt...\n",
            "Loading T2_resnet18_class_balanced.pt...\n",
            "Loading T2_resnet18_focal_loss.pt...\n",
            "Loading T3_best_resnet18_task3_mha.pt...\n",
            "Loading T3_best_resnet18_task3_se.pt...\n",
            "\n",
            " Model Weights:\n",
            "  T1_efficientnet_DLsns_task1-1.pt        : 0.0833\n",
            "  T1_efficientnet_DLsns_task1-2.pt        : 0.0833\n",
            "  T1_efficientnet_DLsns_task1-3.pt        : 0.0833\n",
            "  T1_resnet18_DLsns_task1-1.pt            : 0.0833\n",
            "  T1_resnet18_DLsns_task1-2.pt            : 0.0833\n",
            "  T1_resnet18_DLsns_task1-3.pt            : 0.0833\n",
            "  T2_efficientnet_class_balanced.pt       : 0.0833\n",
            "  T2_efficientnet_focal_loss.pt           : 0.0833\n",
            "  T2_resnet18_class_balanced.pt           : 0.0833\n",
            "  T2_resnet18_focal_loss.pt               : 0.0833\n",
            "  T3_best_resnet18_task3_mha.pt           : 0.0833\n",
            "  T3_best_resnet18_task3_se.pt            : 0.0833\n",
            "\n",
            " Evaluating on offsite test set...\n",
            "\n",
            "======================================================================\n",
            " Offsite Test Results\n",
            "======================================================================\n",
            "\n",
            "DR        : Precision=0.9085, Recall=0.9214, F1=0.9149\n",
            "Glaucoma  : Precision=0.8095, Recall=0.6939, F1=0.7473\n",
            "AMD       : Precision=0.8333, Recall=0.6818, F1=0.7500\n",
            "\n",
            "======================================================================\n",
            " Average F1-score: 0.8040 (80.40%)\n",
            "======================================================================\n",
            "\n",
            " Generating onsite test predictions...\n",
            " Saved predictions: task4_ultimate_weighted_tta.csv\n",
            "\n",
            "\n",
            "======================================================================\n",
            " ULTIMATE METHOD 1: Super Weighted Ensemble\n",
            "======================================================================\n",
            "Total models: 12\n",
            "Test-Time Augmentation: False\n",
            "======================================================================\n",
            "\n",
            "Loading T1_efficientnet_DLsns_task1-1.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-2.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-3.pt...\n",
            "Loading T1_resnet18_DLsns_task1-1.pt...\n",
            "Loading T1_resnet18_DLsns_task1-2.pt...\n",
            "Loading T1_resnet18_DLsns_task1-3.pt...\n",
            "Loading T2_efficientnet_class_balanced.pt...\n",
            "Loading T2_efficientnet_focal_loss.pt...\n",
            "Loading T2_resnet18_class_balanced.pt...\n",
            "Loading T2_resnet18_focal_loss.pt...\n",
            "Loading T3_best_resnet18_task3_mha.pt...\n",
            "Loading T3_best_resnet18_task3_se.pt...\n",
            "\n",
            " Model Weights:\n",
            "  T1_efficientnet_DLsns_task1-1.pt        : 0.0833\n",
            "  T1_efficientnet_DLsns_task1-2.pt        : 0.0833\n",
            "  T1_efficientnet_DLsns_task1-3.pt        : 0.0833\n",
            "  T1_resnet18_DLsns_task1-1.pt            : 0.0833\n",
            "  T1_resnet18_DLsns_task1-2.pt            : 0.0833\n",
            "  T1_resnet18_DLsns_task1-3.pt            : 0.0833\n",
            "  T2_efficientnet_class_balanced.pt       : 0.0833\n",
            "  T2_efficientnet_focal_loss.pt           : 0.0833\n",
            "  T2_resnet18_class_balanced.pt           : 0.0833\n",
            "  T2_resnet18_focal_loss.pt               : 0.0833\n",
            "  T3_best_resnet18_task3_mha.pt           : 0.0833\n",
            "  T3_best_resnet18_task3_se.pt            : 0.0833\n",
            "\n",
            " Evaluating on offsite test set...\n",
            "\n",
            "======================================================================\n",
            " Offsite Test Results\n",
            "======================================================================\n",
            "\n",
            "DR        : Precision=0.9143, Recall=0.9143, F1=0.9143\n",
            "Glaucoma  : Precision=0.8293, Recall=0.6939, F1=0.7556\n",
            "AMD       : Precision=0.8333, Recall=0.6818, F1=0.7500\n",
            "\n",
            "======================================================================\n",
            " Average F1-score: 0.8066 (80.66%)\n",
            "======================================================================\n",
            "\n",
            " Generating onsite test predictions...\n",
            " Saved predictions: task4_ultimate_weighted_no_tta.csv\n",
            "\n",
            "\n",
            "======================================================================\n",
            " ULTIMATE METHOD 2: Deep Stacking Ensemble\n",
            "======================================================================\n",
            "Base models: 12\n",
            "Meta-learner: Random Forest\n",
            "======================================================================\n",
            "\n",
            "Loading T1_efficientnet_DLsns_task1-1.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-2.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-3.pt...\n",
            "Loading T1_resnet18_DLsns_task1-1.pt...\n",
            "Loading T1_resnet18_DLsns_task1-2.pt...\n",
            "Loading T1_resnet18_DLsns_task1-3.pt...\n",
            "Loading T2_efficientnet_class_balanced.pt...\n",
            "Loading T2_efficientnet_focal_loss.pt...\n",
            "Loading T2_resnet18_class_balanced.pt...\n",
            "Loading T2_resnet18_focal_loss.pt...\n",
            "Loading T3_best_resnet18_task3_mha.pt...\n",
            "Loading T3_best_resnet18_task3_se.pt...\n",
            "\n",
            " Generating meta-features...\n",
            "  Generating predictions for train...\n",
            "  Generating predictions for validation...\n",
            "  Generating predictions for test...\n",
            "\n",
            "  Meta-feature shape: (800, 36)\n",
            "\n",
            " Training Meta-Learners...\n",
            "\n",
            "  DR:\n",
            "    Validation F1: 0.8546\n",
            "\n",
            "  Glaucoma:\n",
            "    Validation F1: 0.8224\n",
            "\n",
            "  AMD:\n",
            "    Validation F1: 0.7595\n",
            "\n",
            "======================================================================\n",
            " Offsite Test Results\n",
            "======================================================================\n",
            "\n",
            "DR        : Precision=0.9389, Recall=0.8786, F1=0.9077\n",
            "Glaucoma  : Precision=0.8085, Recall=0.7755, F1=0.7917\n",
            "AMD       : Precision=0.6957, Recall=0.7273, F1=0.7111\n",
            "\n",
            "======================================================================\n",
            " Average F1-score: 0.8035 (80.35%)\n",
            "======================================================================\n",
            "\n",
            " Generating onsite test predictions...\n",
            "  Generating predictions for onsite...\n",
            " Saved predictions: task4_ultimate_stacking.csv\n",
            "\n",
            "\n",
            "======================================================================\n",
            " ULTIMATE METHOD 3: Adaptive Threshold Optimization\n",
            "======================================================================\n",
            "Total models: 12\n",
            "======================================================================\n",
            "\n",
            "Loading T1_efficientnet_DLsns_task1-1.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-2.pt...\n",
            "Loading T1_efficientnet_DLsns_task1-3.pt...\n",
            "Loading T1_resnet18_DLsns_task1-1.pt...\n",
            "Loading T1_resnet18_DLsns_task1-2.pt...\n",
            "Loading T1_resnet18_DLsns_task1-3.pt...\n",
            "Loading T2_efficientnet_class_balanced.pt...\n",
            "Loading T2_efficientnet_focal_loss.pt...\n",
            "Loading T2_resnet18_class_balanced.pt...\n",
            "Loading T2_resnet18_focal_loss.pt...\n",
            "Loading T3_best_resnet18_task3_mha.pt...\n",
            "Loading T3_best_resnet18_task3_se.pt...\n",
            "\n",
            " Finding optimal thresholds on validation set...\n",
            "\n",
            " Optimal thresholds per disease:\n",
            "  DR        : 0.525 (Val F1=0.8559)\n",
            "  Glaucoma  : 0.400 (Val F1=0.8571)\n",
            "  AMD       : 0.450 (Val F1=0.7532)\n",
            "\n",
            "======================================================================\n",
            " Evaluating on offsite test set...\n",
            "======================================================================\n",
            "\n",
            "Offsite Test Results:\n",
            "\n",
            "DR        : Precision=0.9254, Recall=0.8857, F1=0.9051 (threshold=0.525)\n",
            "Glaucoma  : Precision=0.7547, Recall=0.8163, F1=0.7843 (threshold=0.400)\n",
            "AMD       : Precision=0.7500, Recall=0.6818, F1=0.7143 (threshold=0.450)\n",
            "\n",
            "======================================================================\n",
            " Average F1-score: 0.8012 (80.12%)\n",
            "======================================================================\n",
            "\n",
            " Generating onsite test predictions...\n",
            " Saved predictions: task4_ultimate_adaptive.csv\n",
            "\n",
            "\n",
            "======================================================================\n",
            " TASK 4 COMPLETE - ULTIMATE FINAL SUMMARY (All Tasks 1+2+3 Models)\n",
            "======================================================================\n",
            "\n",
            "Offsite Test Results:\n",
            "  ultimate_weighted_tta         : F1 = 0.8040 (80.40%)\n",
            "  ultimate_weighted_no_tta      : F1 = 0.8066 (80.66%)\n",
            "  ultimate_stacking             : F1 = 0.8035 (80.35%)\n",
            "  ultimate_adaptive_threshold   : F1 = 0.8012 (80.12%)\n",
            "\n",
            " Best Method: ULTIMATE_WEIGHTED_NO_TTA with F1 = 0.8066 (80.66%)\n",
            "======================================================================\n",
            "\n",
            "Generated submission files:\n",
            "  - task4_ultimate_weighted_tta.csv\n",
            "  - task4_ultimate_weighted_no_tta.csv\n",
            "  - task4_ultimate_stacking.csv\n",
            "  - task4_ultimate_adaptive.csv\n",
            "\n",
            " Submit this file to Kaggle for best results:\n",
            "  - task4_ultimate_weighted_no_tta.csv\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rAD4zfDMV472"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}